{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and save embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim requires text input to be in sentence format, ie a list containing multiple sentences, where each sentence is a list of tokenized words in that sentence. We can create that fairly easily with a simple function and nltk tokenization. Word2Vec does not require removal of stopwords, since the most frequently occuring words are downsampled anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont need to remove stop words with full w2v - very frequent words get downsampled anyway\n",
    "def text_to_sentence(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        clean = file.read().lower()\n",
    "  \n",
    "    print('Processing '+file_path+'...')\n",
    "    sentences = nltk.sent_tokenize(clean)\n",
    "    print('Sentences tokenized. Tokenizing words...')\n",
    "    sentences = [re.sub('[^a-z]',' ', sentence) for sentence in sentences] \n",
    "    sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    print('done\\n')\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../Data/Female_Authors.txt...\n",
      "Sentences tokenized. Tokenizing words...\n",
      "done\n",
      "\n",
      "Processing ../Data/Male_Authors.txt...\n",
      "Sentences tokenized. Tokenizing words...\n",
      "done\n",
      "\n",
      "Processing ../Data/Movie_Scripts.txt...\n",
      "Sentences tokenized. Tokenizing words...\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "female_text = text_to_sentence('../Data/Female_Authors.txt')\n",
    "male_text = text_to_sentence('../Data/Male_Authors.txt')\n",
    "movie_text = text_to_sentence('../Data/Movie_Scripts.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lyrics dataset requires special processing. The raw data was unpunctuated and doesn't follow a normal\n",
    "# sentence structure. Instead, we will artificially create sentences assuming a standard sentence length of\n",
    "# 6 words, as an estimate of the length of a normal line of lyrics\n",
    "\n",
    "with open('./Data/Combined_lyrics_final.txt', 'r') as file:\n",
    "    clean = file.read().lower()\n",
    "words = nltk.word_tokenize(clean)\n",
    "words = [re.sub('[^a-z]',' ', word) for word in words]\n",
    "lyrics_text = [words[x:x+6] for x in range(0, len(words), 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:12:33,657 : INFO : collecting all words and their counts\n",
      "2019-05-28 18:12:33,659 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-28 18:12:33,727 : INFO : PROGRESS: at sentence #10000, processed 205157 words, keeping 8134 word types\n",
      "2019-05-28 18:12:33,784 : INFO : PROGRESS: at sentence #20000, processed 405666 words, keeping 10477 word types\n",
      "2019-05-28 18:12:33,851 : INFO : PROGRESS: at sentence #30000, processed 640469 words, keeping 13419 word types\n",
      "2019-05-28 18:12:33,900 : INFO : PROGRESS: at sentence #40000, processed 804204 words, keeping 18522 word types\n",
      "2019-05-28 18:12:33,959 : INFO : PROGRESS: at sentence #50000, processed 994638 words, keeping 20714 word types\n",
      "2019-05-28 18:12:34,017 : INFO : PROGRESS: at sentence #60000, processed 1185192 words, keeping 23756 word types\n",
      "2019-05-28 18:12:34,071 : INFO : PROGRESS: at sentence #70000, processed 1371462 words, keeping 26490 word types\n",
      "2019-05-28 18:12:34,126 : INFO : PROGRESS: at sentence #80000, processed 1554673 words, keeping 29076 word types\n",
      "2019-05-28 18:12:34,171 : INFO : PROGRESS: at sentence #90000, processed 1694929 words, keeping 30283 word types\n",
      "2019-05-28 18:12:34,235 : INFO : PROGRESS: at sentence #100000, processed 1905656 words, keeping 31994 word types\n",
      "2019-05-28 18:12:34,296 : INFO : PROGRESS: at sentence #110000, processed 2116101 words, keeping 33969 word types\n",
      "2019-05-28 18:12:34,365 : INFO : PROGRESS: at sentence #120000, processed 2356957 words, keeping 35480 word types\n",
      "2019-05-28 18:12:34,438 : INFO : PROGRESS: at sentence #130000, processed 2615335 words, keeping 37726 word types\n",
      "2019-05-28 18:12:34,515 : INFO : PROGRESS: at sentence #140000, processed 2878605 words, keeping 39349 word types\n",
      "2019-05-28 18:12:34,581 : INFO : PROGRESS: at sentence #150000, processed 3096180 words, keeping 40633 word types\n",
      "2019-05-28 18:12:34,654 : INFO : PROGRESS: at sentence #160000, processed 3342735 words, keeping 42320 word types\n",
      "2019-05-28 18:12:34,730 : INFO : PROGRESS: at sentence #170000, processed 3580330 words, keeping 43376 word types\n",
      "2019-05-28 18:12:34,807 : INFO : PROGRESS: at sentence #180000, processed 3823936 words, keeping 44607 word types\n",
      "2019-05-28 18:12:34,809 : INFO : collected 44607 word types from a corpus of 3826139 raw words and 180080 sentences\n",
      "2019-05-28 18:12:34,810 : INFO : Loading a fresh vocabulary\n",
      "2019-05-28 18:12:34,915 : INFO : min_count=2 retains 31131 unique words (69% of original 44607, drops 13476)\n",
      "2019-05-28 18:12:34,916 : INFO : min_count=2 leaves 3812663 word corpus (99% of original 3826139, drops 13476)\n",
      "2019-05-28 18:12:35,009 : INFO : deleting the raw counts dictionary of 44607 items\n",
      "2019-05-28 18:12:35,012 : INFO : sample=0.001 downsamples 53 most-common words\n",
      "2019-05-28 18:12:35,012 : INFO : downsampling leaves estimated 2806806 word corpus (73.6% of prior 3812663)\n",
      "2019-05-28 18:12:35,120 : INFO : estimated required memory for 31131 words and 100 dimensions: 40470300 bytes\n",
      "2019-05-28 18:12:35,121 : INFO : resetting layer weights\n",
      "2019-05-28 18:12:35,453 : INFO : training model with 8 workers on 31131 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-05-28 18:12:36,471 : INFO : EPOCH 1 - PROGRESS: at 58.80% examples, 1487791 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:12:37,276 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:37,279 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:37,282 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:37,288 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:37,291 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:37,293 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:37,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:37,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:37,297 : INFO : EPOCH - 1 : training on 3826139 raw words (2806531 effective words) took 1.8s, 1537075 effective words/s\n",
      "2019-05-28 18:12:38,315 : INFO : EPOCH 2 - PROGRESS: at 63.29% examples, 1612229 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:12:39,080 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:39,084 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:39,086 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:39,087 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:39,087 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:39,090 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:39,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:39,097 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:39,098 : INFO : EPOCH - 2 : training on 3826139 raw words (2806879 effective words) took 1.8s, 1569361 effective words/s\n",
      "2019-05-28 18:12:40,118 : INFO : EPOCH 3 - PROGRESS: at 61.59% examples, 1558416 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:40,825 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:40,827 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:40,835 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:40,836 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:40,840 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:40,841 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:40,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:40,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:40,849 : INFO : EPOCH - 3 : training on 3826139 raw words (2807375 effective words) took 1.7s, 1614528 effective words/s\n",
      "2019-05-28 18:12:41,870 : INFO : EPOCH 4 - PROGRESS: at 63.86% examples, 1621933 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:42,535 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:42,540 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:42,542 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:42,542 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:42,544 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:42,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:42,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:42,553 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:42,554 : INFO : EPOCH - 4 : training on 3826139 raw words (2805853 effective words) took 1.7s, 1657895 effective words/s\n",
      "2019-05-28 18:12:43,569 : INFO : EPOCH 5 - PROGRESS: at 64.78% examples, 1658899 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:44,224 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:44,229 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:44,235 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:44,236 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:44,240 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:44,241 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:44,242 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:44,250 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:44,251 : INFO : EPOCH - 5 : training on 3826139 raw words (2806390 effective words) took 1.7s, 1665664 effective words/s\n",
      "2019-05-28 18:12:44,252 : INFO : training on a 19130695 raw words (14033028 effective words) took 8.8s, 1594995 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:12:44,253 : INFO : collecting all words and their counts\n",
      "2019-05-28 18:12:44,253 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-28 18:12:44,307 : INFO : PROGRESS: at sentence #10000, processed 174860 words, keeping 11141 word types\n",
      "2019-05-28 18:12:44,366 : INFO : PROGRESS: at sentence #20000, processed 367988 words, keeping 15332 word types\n",
      "2019-05-28 18:12:44,419 : INFO : PROGRESS: at sentence #30000, processed 544829 words, keeping 18554 word types\n",
      "2019-05-28 18:12:44,471 : INFO : PROGRESS: at sentence #40000, processed 721609 words, keeping 20118 word types\n",
      "2019-05-28 18:12:44,527 : INFO : PROGRESS: at sentence #50000, processed 910107 words, keeping 21665 word types\n",
      "2019-05-28 18:12:44,582 : INFO : PROGRESS: at sentence #60000, processed 1094806 words, keeping 23128 word types\n",
      "2019-05-28 18:12:44,636 : INFO : PROGRESS: at sentence #70000, processed 1269560 words, keeping 24622 word types\n",
      "2019-05-28 18:12:44,688 : INFO : PROGRESS: at sentence #80000, processed 1448511 words, keeping 25840 word types\n",
      "2019-05-28 18:12:44,750 : INFO : PROGRESS: at sentence #90000, processed 1637459 words, keeping 27411 word types\n",
      "2019-05-28 18:12:44,807 : INFO : PROGRESS: at sentence #100000, processed 1802883 words, keeping 29050 word types\n",
      "2019-05-28 18:12:44,878 : INFO : PROGRESS: at sentence #110000, processed 2009650 words, keeping 31431 word types\n",
      "2019-05-28 18:12:44,948 : INFO : PROGRESS: at sentence #120000, processed 2210712 words, keeping 34231 word types\n",
      "2019-05-28 18:12:45,022 : INFO : PROGRESS: at sentence #130000, processed 2427237 words, keeping 36323 word types\n",
      "2019-05-28 18:12:45,098 : INFO : PROGRESS: at sentence #140000, processed 2644690 words, keeping 38017 word types\n",
      "2019-05-28 18:12:45,172 : INFO : PROGRESS: at sentence #150000, processed 2865818 words, keeping 40629 word types\n",
      "2019-05-28 18:12:45,242 : INFO : PROGRESS: at sentence #160000, processed 3068238 words, keeping 43067 word types\n",
      "2019-05-28 18:12:45,326 : INFO : PROGRESS: at sentence #170000, processed 3323468 words, keeping 45132 word types\n",
      "2019-05-28 18:12:45,376 : INFO : PROGRESS: at sentence #180000, processed 3478308 words, keeping 46998 word types\n",
      "2019-05-28 18:12:45,425 : INFO : PROGRESS: at sentence #190000, processed 3636360 words, keeping 49062 word types\n",
      "2019-05-28 18:12:45,483 : INFO : PROGRESS: at sentence #200000, processed 3827188 words, keeping 51063 word types\n",
      "2019-05-28 18:12:45,549 : INFO : PROGRESS: at sentence #210000, processed 4043245 words, keeping 52734 word types\n",
      "2019-05-28 18:12:45,605 : INFO : PROGRESS: at sentence #220000, processed 4234186 words, keeping 53761 word types\n",
      "2019-05-28 18:12:45,649 : INFO : PROGRESS: at sentence #230000, processed 4365585 words, keeping 54567 word types\n",
      "2019-05-28 18:12:45,701 : INFO : PROGRESS: at sentence #240000, processed 4509614 words, keeping 55466 word types\n",
      "2019-05-28 18:12:45,728 : INFO : collected 55885 word types from a corpus of 4586712 raw words and 244736 sentences\n",
      "2019-05-28 18:12:45,728 : INFO : Loading a fresh vocabulary\n",
      "2019-05-28 18:12:45,843 : INFO : min_count=2 retains 38932 unique words (69% of original 55885, drops 16953)\n",
      "2019-05-28 18:12:45,844 : INFO : min_count=2 leaves 4569759 word corpus (99% of original 4586712, drops 16953)\n",
      "2019-05-28 18:12:45,972 : INFO : deleting the raw counts dictionary of 55885 items\n",
      "2019-05-28 18:12:45,974 : INFO : sample=0.001 downsamples 56 most-common words\n",
      "2019-05-28 18:12:45,975 : INFO : downsampling leaves estimated 3392850 word corpus (74.2% of prior 4569759)\n",
      "2019-05-28 18:12:46,084 : INFO : estimated required memory for 38932 words and 100 dimensions: 50611600 bytes\n",
      "2019-05-28 18:12:46,084 : INFO : resetting layer weights\n",
      "2019-05-28 18:12:46,470 : INFO : training model with 8 workers on 38932 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-05-28 18:12:47,489 : INFO : EPOCH 1 - PROGRESS: at 47.19% examples, 1549378 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:48,492 : INFO : EPOCH 1 - PROGRESS: at 90.78% examples, 1566603 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:48,617 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:48,626 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:48,627 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:48,628 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:48,632 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:48,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:48,637 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:48,638 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:48,639 : INFO : EPOCH - 1 : training on 4586712 raw words (3392284 effective words) took 2.2s, 1572173 effective words/s\n",
      "2019-05-28 18:12:49,660 : INFO : EPOCH 2 - PROGRESS: at 48.75% examples, 1608499 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:50,661 : INFO : EPOCH 2 - PROGRESS: at 93.56% examples, 1602396 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:50,743 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:50,744 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:50,745 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:50,746 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:50,747 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:50,747 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:50,755 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:50,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:50,758 : INFO : EPOCH - 2 : training on 4586712 raw words (3393586 effective words) took 2.1s, 1611433 effective words/s\n",
      "2019-05-28 18:12:51,778 : INFO : EPOCH 3 - PROGRESS: at 48.72% examples, 1609677 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-28 18:12:52,781 : INFO : EPOCH 3 - PROGRESS: at 93.90% examples, 1605003 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:52,850 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:52,866 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:52,869 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:52,871 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:52,872 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:52,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:52,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:52,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:52,881 : INFO : EPOCH - 3 : training on 4586712 raw words (3393316 effective words) took 2.1s, 1608665 effective words/s\n",
      "2019-05-28 18:12:53,900 : INFO : EPOCH 4 - PROGRESS: at 48.18% examples, 1597236 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:54,904 : INFO : EPOCH 4 - PROGRESS: at 91.93% examples, 1583120 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:12:55,008 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:55,010 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:55,012 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:55,017 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:55,023 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:55,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:55,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:55,028 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:55,029 : INFO : EPOCH - 4 : training on 4586712 raw words (3393702 effective words) took 2.1s, 1593231 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:12:56,050 : INFO : EPOCH 5 - PROGRESS: at 49.62% examples, 1642047 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-28 18:12:57,052 : INFO : EPOCH 5 - PROGRESS: at 94.72% examples, 1615818 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:12:57,108 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:12:57,113 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:12:57,119 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:12:57,126 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:12:57,129 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:12:57,135 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:12:57,136 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:12:57,137 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:12:57,138 : INFO : EPOCH - 5 : training on 4586712 raw words (3392950 effective words) took 2.1s, 1618468 effective words/s\n",
      "2019-05-28 18:12:57,139 : INFO : training on a 22933560 raw words (16965838 effective words) took 10.7s, 1590337 effective words/s\n",
      "2019-05-28 18:12:57,140 : INFO : collecting all words and their counts\n",
      "2019-05-28 18:12:57,141 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-28 18:12:57,168 : INFO : PROGRESS: at sentence #10000, processed 78442 words, keeping 8167 word types\n",
      "2019-05-28 18:12:57,196 : INFO : PROGRESS: at sentence #20000, processed 158876 words, keeping 10947 word types\n",
      "2019-05-28 18:12:57,225 : INFO : PROGRESS: at sentence #30000, processed 240489 words, keeping 14400 word types\n",
      "2019-05-28 18:12:57,250 : INFO : PROGRESS: at sentence #40000, processed 305680 words, keeping 16285 word types\n",
      "2019-05-28 18:12:57,286 : INFO : PROGRESS: at sentence #50000, processed 401258 words, keeping 18179 word types\n",
      "2019-05-28 18:12:57,317 : INFO : PROGRESS: at sentence #60000, processed 490158 words, keeping 20287 word types\n",
      "2019-05-28 18:12:57,344 : INFO : PROGRESS: at sentence #70000, processed 561052 words, keeping 21742 word types\n",
      "2019-05-28 18:12:57,374 : INFO : PROGRESS: at sentence #80000, processed 639221 words, keeping 23307 word types\n",
      "2019-05-28 18:12:57,404 : INFO : PROGRESS: at sentence #90000, processed 709635 words, keeping 24597 word types\n",
      "2019-05-28 18:12:57,441 : INFO : PROGRESS: at sentence #100000, processed 797667 words, keeping 25887 word types\n",
      "2019-05-28 18:12:57,468 : INFO : PROGRESS: at sentence #110000, processed 868830 words, keeping 27064 word types\n",
      "2019-05-28 18:12:57,501 : INFO : PROGRESS: at sentence #120000, processed 958571 words, keeping 28474 word types\n",
      "2019-05-28 18:12:57,534 : INFO : PROGRESS: at sentence #130000, processed 1035408 words, keeping 29493 word types\n",
      "2019-05-28 18:12:57,565 : INFO : PROGRESS: at sentence #140000, processed 1120620 words, keeping 30777 word types\n",
      "2019-05-28 18:12:57,596 : INFO : PROGRESS: at sentence #150000, processed 1199410 words, keeping 31609 word types\n",
      "2019-05-28 18:12:57,628 : INFO : PROGRESS: at sentence #160000, processed 1279190 words, keeping 32446 word types\n",
      "2019-05-28 18:12:57,668 : INFO : PROGRESS: at sentence #170000, processed 1356239 words, keeping 33062 word types\n",
      "2019-05-28 18:12:57,701 : INFO : PROGRESS: at sentence #180000, processed 1433133 words, keeping 33838 word types\n",
      "2019-05-28 18:12:57,738 : INFO : PROGRESS: at sentence #190000, processed 1521581 words, keeping 35082 word types\n",
      "2019-05-28 18:12:57,772 : INFO : PROGRESS: at sentence #200000, processed 1602935 words, keeping 35990 word types\n",
      "2019-05-28 18:12:57,804 : INFO : PROGRESS: at sentence #210000, processed 1675199 words, keeping 36534 word types\n",
      "2019-05-28 18:12:57,832 : INFO : PROGRESS: at sentence #220000, processed 1742642 words, keeping 36768 word types\n",
      "2019-05-28 18:12:57,867 : INFO : PROGRESS: at sentence #230000, processed 1826829 words, keeping 37313 word types\n",
      "2019-05-28 18:12:57,897 : INFO : PROGRESS: at sentence #240000, processed 1902865 words, keeping 37910 word types\n",
      "2019-05-28 18:12:57,926 : INFO : PROGRESS: at sentence #250000, processed 1976194 words, keeping 38420 word types\n",
      "2019-05-28 18:12:57,956 : INFO : PROGRESS: at sentence #260000, processed 2053638 words, keeping 39012 word types\n",
      "2019-05-28 18:12:57,986 : INFO : PROGRESS: at sentence #270000, processed 2136298 words, keeping 39558 word types\n",
      "2019-05-28 18:12:58,013 : INFO : PROGRESS: at sentence #280000, processed 2210994 words, keeping 40030 word types\n",
      "2019-05-28 18:12:58,042 : INFO : PROGRESS: at sentence #290000, processed 2288099 words, keeping 40470 word types\n",
      "2019-05-28 18:12:58,070 : INFO : PROGRESS: at sentence #300000, processed 2357370 words, keeping 40868 word types\n",
      "2019-05-28 18:12:58,105 : INFO : PROGRESS: at sentence #310000, processed 2442566 words, keeping 41187 word types\n",
      "2019-05-28 18:12:58,131 : INFO : PROGRESS: at sentence #320000, processed 2517560 words, keeping 41996 word types\n",
      "2019-05-28 18:12:58,159 : INFO : PROGRESS: at sentence #330000, processed 2598119 words, keeping 42547 word types\n",
      "2019-05-28 18:12:58,190 : INFO : PROGRESS: at sentence #340000, processed 2680327 words, keeping 43203 word types\n",
      "2019-05-28 18:12:58,221 : INFO : PROGRESS: at sentence #350000, processed 2753388 words, keeping 43612 word types\n",
      "2019-05-28 18:12:58,261 : INFO : PROGRESS: at sentence #360000, processed 2827773 words, keeping 44075 word types\n",
      "2019-05-28 18:12:58,291 : INFO : PROGRESS: at sentence #370000, processed 2901762 words, keeping 44521 word types\n",
      "2019-05-28 18:12:58,321 : INFO : PROGRESS: at sentence #380000, processed 2978655 words, keeping 44741 word types\n",
      "2019-05-28 18:12:58,355 : INFO : PROGRESS: at sentence #390000, processed 3059763 words, keeping 45397 word types\n",
      "2019-05-28 18:12:58,388 : INFO : PROGRESS: at sentence #400000, processed 3142993 words, keeping 45817 word types\n",
      "2019-05-28 18:12:58,418 : INFO : PROGRESS: at sentence #410000, processed 3214269 words, keeping 46088 word types\n",
      "2019-05-28 18:12:58,445 : INFO : PROGRESS: at sentence #420000, processed 3280203 words, keeping 46374 word types\n",
      "2019-05-28 18:12:58,477 : INFO : PROGRESS: at sentence #430000, processed 3373724 words, keeping 47119 word types\n",
      "2019-05-28 18:12:58,508 : INFO : PROGRESS: at sentence #440000, processed 3452626 words, keeping 47464 word types\n",
      "2019-05-28 18:12:58,540 : INFO : PROGRESS: at sentence #450000, processed 3537444 words, keeping 48061 word types\n",
      "2019-05-28 18:12:58,569 : INFO : PROGRESS: at sentence #460000, processed 3608439 words, keeping 48380 word types\n",
      "2019-05-28 18:12:58,602 : INFO : PROGRESS: at sentence #470000, processed 3698092 words, keeping 48986 word types\n",
      "2019-05-28 18:12:58,636 : INFO : PROGRESS: at sentence #480000, processed 3789825 words, keeping 49580 word types\n",
      "2019-05-28 18:12:58,665 : INFO : PROGRESS: at sentence #490000, processed 3876514 words, keeping 49959 word types\n",
      "2019-05-28 18:12:58,697 : INFO : PROGRESS: at sentence #500000, processed 3957409 words, keeping 50361 word types\n",
      "2019-05-28 18:12:58,729 : INFO : PROGRESS: at sentence #510000, processed 4046796 words, keeping 50811 word types\n",
      "2019-05-28 18:12:58,760 : INFO : PROGRESS: at sentence #520000, processed 4131899 words, keeping 51264 word types\n",
      "2019-05-28 18:12:58,789 : INFO : PROGRESS: at sentence #530000, processed 4212460 words, keeping 51567 word types\n",
      "2019-05-28 18:12:58,816 : INFO : PROGRESS: at sentence #540000, processed 4288312 words, keeping 52180 word types\n",
      "2019-05-28 18:12:58,859 : INFO : PROGRESS: at sentence #550000, processed 4375154 words, keeping 52759 word types\n",
      "2019-05-28 18:12:58,892 : INFO : PROGRESS: at sentence #560000, processed 4456579 words, keeping 53166 word types\n",
      "2019-05-28 18:12:58,922 : INFO : PROGRESS: at sentence #570000, processed 4535707 words, keeping 53387 word types\n",
      "2019-05-28 18:12:58,950 : INFO : PROGRESS: at sentence #580000, processed 4613919 words, keeping 53668 word types\n",
      "2019-05-28 18:12:58,985 : INFO : PROGRESS: at sentence #590000, processed 4689158 words, keeping 54095 word types\n",
      "2019-05-28 18:12:59,014 : INFO : PROGRESS: at sentence #600000, processed 4767677 words, keeping 54364 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:12:59,048 : INFO : PROGRESS: at sentence #610000, processed 4859454 words, keeping 55097 word types\n",
      "2019-05-28 18:12:59,082 : INFO : PROGRESS: at sentence #620000, processed 4940068 words, keeping 55369 word types\n",
      "2019-05-28 18:12:59,116 : INFO : PROGRESS: at sentence #630000, processed 5030982 words, keeping 55668 word types\n",
      "2019-05-28 18:12:59,144 : INFO : PROGRESS: at sentence #640000, processed 5099035 words, keeping 55957 word types\n",
      "2019-05-28 18:12:59,179 : INFO : PROGRESS: at sentence #650000, processed 5193045 words, keeping 56191 word types\n",
      "2019-05-28 18:12:59,208 : INFO : PROGRESS: at sentence #660000, processed 5265438 words, keeping 56341 word types\n",
      "2019-05-28 18:12:59,241 : INFO : PROGRESS: at sentence #670000, processed 5347950 words, keeping 56987 word types\n",
      "2019-05-28 18:12:59,274 : INFO : PROGRESS: at sentence #680000, processed 5429685 words, keeping 57363 word types\n",
      "2019-05-28 18:12:59,309 : INFO : PROGRESS: at sentence #690000, processed 5519481 words, keeping 57790 word types\n",
      "2019-05-28 18:12:59,339 : INFO : PROGRESS: at sentence #700000, processed 5598504 words, keeping 58181 word types\n",
      "2019-05-28 18:12:59,374 : INFO : PROGRESS: at sentence #710000, processed 5684553 words, keeping 58697 word types\n",
      "2019-05-28 18:12:59,404 : INFO : PROGRESS: at sentence #720000, processed 5764222 words, keeping 59266 word types\n",
      "2019-05-28 18:12:59,433 : INFO : PROGRESS: at sentence #730000, processed 5837129 words, keeping 59446 word types\n",
      "2019-05-28 18:12:59,464 : INFO : PROGRESS: at sentence #740000, processed 5921513 words, keeping 59789 word types\n",
      "2019-05-28 18:12:59,487 : INFO : PROGRESS: at sentence #750000, processed 5991236 words, keeping 60045 word types\n",
      "2019-05-28 18:12:59,521 : INFO : PROGRESS: at sentence #760000, processed 6075029 words, keeping 60373 word types\n",
      "2019-05-28 18:12:59,552 : INFO : PROGRESS: at sentence #770000, processed 6161021 words, keeping 60641 word types\n",
      "2019-05-28 18:12:59,585 : INFO : PROGRESS: at sentence #780000, processed 6247100 words, keeping 61012 word types\n",
      "2019-05-28 18:12:59,609 : INFO : PROGRESS: at sentence #790000, processed 6317874 words, keeping 61203 word types\n",
      "2019-05-28 18:12:59,642 : INFO : PROGRESS: at sentence #800000, processed 6402377 words, keeping 61661 word types\n",
      "2019-05-28 18:12:59,670 : INFO : PROGRESS: at sentence #810000, processed 6477576 words, keeping 62075 word types\n",
      "2019-05-28 18:12:59,705 : INFO : PROGRESS: at sentence #820000, processed 6566879 words, keeping 62409 word types\n",
      "2019-05-28 18:12:59,736 : INFO : PROGRESS: at sentence #830000, processed 6645205 words, keeping 62763 word types\n",
      "2019-05-28 18:12:59,769 : INFO : PROGRESS: at sentence #840000, processed 6731851 words, keeping 63093 word types\n",
      "2019-05-28 18:12:59,797 : INFO : PROGRESS: at sentence #850000, processed 6813831 words, keeping 63455 word types\n",
      "2019-05-28 18:12:59,824 : INFO : PROGRESS: at sentence #860000, processed 6880625 words, keeping 63722 word types\n",
      "2019-05-28 18:12:59,859 : INFO : PROGRESS: at sentence #870000, processed 6962673 words, keeping 64128 word types\n",
      "2019-05-28 18:12:59,888 : INFO : PROGRESS: at sentence #880000, processed 7043833 words, keeping 64413 word types\n",
      "2019-05-28 18:12:59,918 : INFO : PROGRESS: at sentence #890000, processed 7132857 words, keeping 64809 word types\n",
      "2019-05-28 18:12:59,949 : INFO : PROGRESS: at sentence #900000, processed 7226283 words, keeping 65079 word types\n",
      "2019-05-28 18:12:59,981 : INFO : PROGRESS: at sentence #910000, processed 7310796 words, keeping 65342 word types\n",
      "2019-05-28 18:13:00,012 : INFO : PROGRESS: at sentence #920000, processed 7382311 words, keeping 65692 word types\n",
      "2019-05-28 18:13:00,046 : INFO : PROGRESS: at sentence #930000, processed 7463137 words, keeping 66257 word types\n",
      "2019-05-28 18:13:00,079 : INFO : PROGRESS: at sentence #940000, processed 7541812 words, keeping 66525 word types\n",
      "2019-05-28 18:13:00,114 : INFO : PROGRESS: at sentence #950000, processed 7632837 words, keeping 66882 word types\n",
      "2019-05-28 18:13:00,144 : INFO : PROGRESS: at sentence #960000, processed 7709568 words, keeping 67055 word types\n",
      "2019-05-28 18:13:00,170 : INFO : PROGRESS: at sentence #970000, processed 7781290 words, keeping 67327 word types\n",
      "2019-05-28 18:13:00,198 : INFO : PROGRESS: at sentence #980000, processed 7852744 words, keeping 67504 word types\n",
      "2019-05-28 18:13:00,232 : INFO : PROGRESS: at sentence #990000, processed 7947026 words, keeping 67833 word types\n",
      "2019-05-28 18:13:00,261 : INFO : PROGRESS: at sentence #1000000, processed 8022907 words, keeping 68055 word types\n",
      "2019-05-28 18:13:00,288 : INFO : PROGRESS: at sentence #1010000, processed 8089469 words, keeping 68304 word types\n",
      "2019-05-28 18:13:00,315 : INFO : PROGRESS: at sentence #1020000, processed 8164168 words, keeping 68456 word types\n",
      "2019-05-28 18:13:00,345 : INFO : PROGRESS: at sentence #1030000, processed 8246898 words, keeping 68659 word types\n",
      "2019-05-28 18:13:00,375 : INFO : PROGRESS: at sentence #1040000, processed 8329115 words, keeping 68862 word types\n",
      "2019-05-28 18:13:00,402 : INFO : PROGRESS: at sentence #1050000, processed 8402759 words, keeping 69137 word types\n",
      "2019-05-28 18:13:00,433 : INFO : PROGRESS: at sentence #1060000, processed 8479113 words, keeping 69285 word types\n",
      "2019-05-28 18:13:00,461 : INFO : PROGRESS: at sentence #1070000, processed 8554559 words, keeping 69492 word types\n",
      "2019-05-28 18:13:00,494 : INFO : PROGRESS: at sentence #1080000, processed 8639462 words, keeping 69858 word types\n",
      "2019-05-28 18:13:00,524 : INFO : PROGRESS: at sentence #1090000, processed 8723025 words, keeping 70064 word types\n",
      "2019-05-28 18:13:00,552 : INFO : PROGRESS: at sentence #1100000, processed 8796576 words, keeping 70387 word types\n",
      "2019-05-28 18:13:00,581 : INFO : PROGRESS: at sentence #1110000, processed 8877592 words, keeping 70823 word types\n",
      "2019-05-28 18:13:00,617 : INFO : PROGRESS: at sentence #1120000, processed 8962962 words, keeping 71045 word types\n",
      "2019-05-28 18:13:00,649 : INFO : PROGRESS: at sentence #1130000, processed 9040815 words, keeping 71404 word types\n",
      "2019-05-28 18:13:00,682 : INFO : PROGRESS: at sentence #1140000, processed 9124071 words, keeping 71624 word types\n",
      "2019-05-28 18:13:00,714 : INFO : PROGRESS: at sentence #1150000, processed 9195553 words, keeping 71861 word types\n",
      "2019-05-28 18:13:00,749 : INFO : PROGRESS: at sentence #1160000, processed 9275758 words, keeping 72017 word types\n",
      "2019-05-28 18:13:00,782 : INFO : PROGRESS: at sentence #1170000, processed 9354400 words, keeping 72124 word types\n",
      "2019-05-28 18:13:00,815 : INFO : PROGRESS: at sentence #1180000, processed 9438893 words, keeping 72125 word types\n",
      "2019-05-28 18:13:00,849 : INFO : PROGRESS: at sentence #1190000, processed 9527070 words, keeping 72417 word types\n",
      "2019-05-28 18:13:00,882 : INFO : PROGRESS: at sentence #1200000, processed 9617428 words, keeping 72751 word types\n",
      "2019-05-28 18:13:00,908 : INFO : PROGRESS: at sentence #1210000, processed 9688266 words, keeping 73035 word types\n",
      "2019-05-28 18:13:00,939 : INFO : PROGRESS: at sentence #1220000, processed 9768198 words, keeping 73481 word types\n",
      "2019-05-28 18:13:00,969 : INFO : PROGRESS: at sentence #1230000, processed 9844737 words, keeping 73658 word types\n",
      "2019-05-28 18:13:00,994 : INFO : PROGRESS: at sentence #1240000, processed 9921196 words, keeping 73790 word types\n",
      "2019-05-28 18:13:01,023 : INFO : PROGRESS: at sentence #1250000, processed 9996775 words, keeping 73918 word types\n",
      "2019-05-28 18:13:01,052 : INFO : PROGRESS: at sentence #1260000, processed 10072310 words, keeping 74030 word types\n",
      "2019-05-28 18:13:01,083 : INFO : PROGRESS: at sentence #1270000, processed 10146714 words, keeping 74355 word types\n",
      "2019-05-28 18:13:01,113 : INFO : PROGRESS: at sentence #1280000, processed 10225862 words, keeping 74579 word types\n",
      "2019-05-28 18:13:01,144 : INFO : PROGRESS: at sentence #1290000, processed 10312545 words, keeping 74700 word types\n",
      "2019-05-28 18:13:01,171 : INFO : PROGRESS: at sentence #1300000, processed 10391318 words, keeping 74996 word types\n",
      "2019-05-28 18:13:01,194 : INFO : collected 75099 word types from a corpus of 10440726 raw words and 1306597 sentences\n",
      "2019-05-28 18:13:01,195 : INFO : Loading a fresh vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:13:01,298 : INFO : min_count=2 retains 52523 unique words (69% of original 75099, drops 22576)\n",
      "2019-05-28 18:13:01,299 : INFO : min_count=2 leaves 10418150 word corpus (99% of original 10440726, drops 22576)\n",
      "2019-05-28 18:13:01,446 : INFO : deleting the raw counts dictionary of 75099 items\n",
      "2019-05-28 18:13:01,449 : INFO : sample=0.001 downsamples 56 most-common words\n",
      "2019-05-28 18:13:01,450 : INFO : downsampling leaves estimated 7987390 word corpus (76.7% of prior 10418150)\n",
      "2019-05-28 18:13:01,593 : INFO : estimated required memory for 52523 words and 100 dimensions: 68279900 bytes\n",
      "2019-05-28 18:13:01,594 : INFO : resetting layer weights\n",
      "2019-05-28 18:13:02,105 : INFO : training model with 8 workers on 52523 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-05-28 18:13:03,128 : INFO : EPOCH 1 - PROGRESS: at 17.35% examples, 1368205 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:04,131 : INFO : EPOCH 1 - PROGRESS: at 36.32% examples, 1427572 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:05,132 : INFO : EPOCH 1 - PROGRESS: at 54.54% examples, 1449565 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:06,136 : INFO : EPOCH 1 - PROGRESS: at 72.86% examples, 1455555 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:07,141 : INFO : EPOCH 1 - PROGRESS: at 91.37% examples, 1456277 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:07,578 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:07,580 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:07,586 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:07,587 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:07,593 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:07,596 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:07,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:07,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:07,599 : INFO : EPOCH - 1 : training on 10440726 raw words (7987877 effective words) took 5.5s, 1457397 effective words/s\n",
      "2019-05-28 18:13:08,618 : INFO : EPOCH 2 - PROGRESS: at 17.44% examples, 1379624 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:09,620 : INFO : EPOCH 2 - PROGRESS: at 36.25% examples, 1425878 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:13:10,623 : INFO : EPOCH 2 - PROGRESS: at 54.37% examples, 1444548 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-28 18:13:11,628 : INFO : EPOCH 2 - PROGRESS: at 72.72% examples, 1453508 words/s, in_qsize 16, out_qsize 0\n",
      "2019-05-28 18:13:12,629 : INFO : EPOCH 2 - PROGRESS: at 91.21% examples, 1454372 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:13:13,040 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:13,048 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:13,054 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:13,055 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:13,057 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:13,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:13,067 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:13,068 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:13,068 : INFO : EPOCH - 2 : training on 10440726 raw words (7987014 effective words) took 5.5s, 1463203 effective words/s\n",
      "2019-05-28 18:13:14,092 : INFO : EPOCH 3 - PROGRESS: at 18.12% examples, 1428030 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:13:15,095 : INFO : EPOCH 3 - PROGRESS: at 37.14% examples, 1460757 words/s, in_qsize 12, out_qsize 3\n",
      "2019-05-28 18:13:16,101 : INFO : EPOCH 3 - PROGRESS: at 55.22% examples, 1464084 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:13:17,102 : INFO : EPOCH 3 - PROGRESS: at 73.33% examples, 1463360 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:18,106 : INFO : EPOCH 3 - PROGRESS: at 92.13% examples, 1467802 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:13:18,468 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:18,476 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:18,481 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:18,483 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:18,484 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:18,495 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:18,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:18,496 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:18,497 : INFO : EPOCH - 3 : training on 10440726 raw words (7988024 effective words) took 5.4s, 1474802 effective words/s\n",
      "2019-05-28 18:13:19,526 : INFO : EPOCH 4 - PROGRESS: at 18.13% examples, 1419725 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-28 18:13:20,532 : INFO : EPOCH 4 - PROGRESS: at 37.07% examples, 1450352 words/s, in_qsize 16, out_qsize 1\n",
      "2019-05-28 18:13:21,533 : INFO : EPOCH 4 - PROGRESS: at 55.22% examples, 1462190 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:13:22,543 : INFO : EPOCH 4 - PROGRESS: at 73.72% examples, 1466433 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:23,547 : INFO : EPOCH 4 - PROGRESS: at 91.66% examples, 1456433 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:13:23,939 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:23,945 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:23,946 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:23,948 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:23,952 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:23,953 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:23,955 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:23,958 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:23,959 : INFO : EPOCH - 4 : training on 10440726 raw words (7986968 effective words) took 5.5s, 1465439 effective words/s\n",
      "2019-05-28 18:13:24,982 : INFO : EPOCH 5 - PROGRESS: at 18.43% examples, 1449515 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-28 18:13:25,997 : INFO : EPOCH 5 - PROGRESS: at 37.14% examples, 1450917 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-28 18:13:27,002 : INFO : EPOCH 5 - PROGRESS: at 55.30% examples, 1460903 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:28,007 : INFO : EPOCH 5 - PROGRESS: at 73.72% examples, 1465437 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-28 18:13:29,011 : INFO : EPOCH 5 - PROGRESS: at 92.44% examples, 1467790 words/s, in_qsize 16, out_qsize 1\n",
      "2019-05-28 18:13:29,359 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:29,361 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:29,371 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:29,376 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:29,377 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:29,378 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:29,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:29,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:29,388 : INFO : EPOCH - 5 : training on 10440726 raw words (7987427 effective words) took 5.4s, 1474294 effective words/s\n",
      "2019-05-28 18:13:29,389 : INFO : training on a 52203630 raw words (39937310 effective words) took 27.3s, 1463767 effective words/s\n",
      "2019-05-28 18:13:29,389 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:13:29,391 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-28 18:13:29,420 : INFO : PROGRESS: at sentence #10000, processed 60000 words, keeping 4447 word types\n",
      "2019-05-28 18:13:29,440 : INFO : PROGRESS: at sentence #20000, processed 120000 words, keeping 6870 word types\n",
      "2019-05-28 18:13:29,461 : INFO : PROGRESS: at sentence #30000, processed 180000 words, keeping 9126 word types\n",
      "2019-05-28 18:13:29,481 : INFO : PROGRESS: at sentence #40000, processed 240000 words, keeping 11075 word types\n",
      "2019-05-28 18:13:29,502 : INFO : PROGRESS: at sentence #50000, processed 300000 words, keeping 12703 word types\n",
      "2019-05-28 18:13:29,522 : INFO : PROGRESS: at sentence #60000, processed 360000 words, keeping 14195 word types\n",
      "2019-05-28 18:13:29,543 : INFO : PROGRESS: at sentence #70000, processed 420000 words, keeping 15920 word types\n",
      "2019-05-28 18:13:29,565 : INFO : PROGRESS: at sentence #80000, processed 480000 words, keeping 17563 word types\n",
      "2019-05-28 18:13:29,584 : INFO : PROGRESS: at sentence #90000, processed 540000 words, keeping 18897 word types\n",
      "2019-05-28 18:13:29,606 : INFO : PROGRESS: at sentence #100000, processed 600000 words, keeping 20358 word types\n",
      "2019-05-28 18:13:29,629 : INFO : PROGRESS: at sentence #110000, processed 660000 words, keeping 22026 word types\n",
      "2019-05-28 18:13:29,649 : INFO : PROGRESS: at sentence #120000, processed 720000 words, keeping 23672 word types\n",
      "2019-05-28 18:13:29,672 : INFO : PROGRESS: at sentence #130000, processed 780000 words, keeping 25164 word types\n",
      "2019-05-28 18:13:29,697 : INFO : PROGRESS: at sentence #140000, processed 840000 words, keeping 26593 word types\n",
      "2019-05-28 18:13:29,717 : INFO : PROGRESS: at sentence #150000, processed 900000 words, keeping 28053 word types\n",
      "2019-05-28 18:13:29,739 : INFO : PROGRESS: at sentence #160000, processed 960000 words, keeping 29268 word types\n",
      "2019-05-28 18:13:29,759 : INFO : PROGRESS: at sentence #170000, processed 1020000 words, keeping 30580 word types\n",
      "2019-05-28 18:13:29,782 : INFO : PROGRESS: at sentence #180000, processed 1080000 words, keeping 31880 word types\n",
      "2019-05-28 18:13:29,805 : INFO : PROGRESS: at sentence #190000, processed 1140000 words, keeping 33162 word types\n",
      "2019-05-28 18:13:29,824 : INFO : PROGRESS: at sentence #200000, processed 1200000 words, keeping 34527 word types\n",
      "2019-05-28 18:13:29,847 : INFO : PROGRESS: at sentence #210000, processed 1260000 words, keeping 35696 word types\n",
      "2019-05-28 18:13:29,872 : INFO : PROGRESS: at sentence #220000, processed 1320000 words, keeping 36769 word types\n",
      "2019-05-28 18:13:29,892 : INFO : PROGRESS: at sentence #230000, processed 1380000 words, keeping 37794 word types\n",
      "2019-05-28 18:13:29,915 : INFO : PROGRESS: at sentence #240000, processed 1440000 words, keeping 38815 word types\n",
      "2019-05-28 18:13:29,938 : INFO : PROGRESS: at sentence #250000, processed 1500000 words, keeping 39954 word types\n",
      "2019-05-28 18:13:29,959 : INFO : PROGRESS: at sentence #260000, processed 1560000 words, keeping 40974 word types\n",
      "2019-05-28 18:13:29,982 : INFO : PROGRESS: at sentence #270000, processed 1620000 words, keeping 41963 word types\n",
      "2019-05-28 18:13:30,000 : INFO : PROGRESS: at sentence #280000, processed 1680000 words, keeping 42648 word types\n",
      "2019-05-28 18:13:30,017 : INFO : PROGRESS: at sentence #290000, processed 1740000 words, keeping 43397 word types\n",
      "2019-05-28 18:13:30,038 : INFO : PROGRESS: at sentence #300000, processed 1800000 words, keeping 43967 word types\n",
      "2019-05-28 18:13:30,054 : INFO : PROGRESS: at sentence #310000, processed 1860000 words, keeping 44488 word types\n",
      "2019-05-28 18:13:30,070 : INFO : PROGRESS: at sentence #320000, processed 1920000 words, keeping 45031 word types\n",
      "2019-05-28 18:13:30,086 : INFO : PROGRESS: at sentence #330000, processed 1980000 words, keeping 45478 word types\n",
      "2019-05-28 18:13:30,105 : INFO : PROGRESS: at sentence #340000, processed 2040000 words, keeping 46016 word types\n",
      "2019-05-28 18:13:30,121 : INFO : PROGRESS: at sentence #350000, processed 2100000 words, keeping 46495 word types\n",
      "2019-05-28 18:13:30,135 : INFO : PROGRESS: at sentence #360000, processed 2160000 words, keeping 46813 word types\n",
      "2019-05-28 18:13:30,151 : INFO : PROGRESS: at sentence #370000, processed 2220000 words, keeping 47265 word types\n",
      "2019-05-28 18:13:30,170 : INFO : PROGRESS: at sentence #380000, processed 2280000 words, keeping 47617 word types\n",
      "2019-05-28 18:13:30,186 : INFO : PROGRESS: at sentence #390000, processed 2340000 words, keeping 47987 word types\n",
      "2019-05-28 18:13:30,202 : INFO : PROGRESS: at sentence #400000, processed 2400000 words, keeping 48326 word types\n",
      "2019-05-28 18:13:30,218 : INFO : PROGRESS: at sentence #410000, processed 2460000 words, keeping 48601 word types\n",
      "2019-05-28 18:13:30,236 : INFO : PROGRESS: at sentence #420000, processed 2520000 words, keeping 48889 word types\n",
      "2019-05-28 18:13:30,252 : INFO : PROGRESS: at sentence #430000, processed 2580000 words, keeping 49218 word types\n",
      "2019-05-28 18:13:30,268 : INFO : PROGRESS: at sentence #440000, processed 2640000 words, keeping 49533 word types\n",
      "2019-05-28 18:13:30,284 : INFO : PROGRESS: at sentence #450000, processed 2700000 words, keeping 49706 word types\n",
      "2019-05-28 18:13:30,293 : INFO : collected 49788 word types from a corpus of 2734842 raw words and 455807 sentences\n",
      "2019-05-28 18:13:30,294 : INFO : Loading a fresh vocabulary\n",
      "2019-05-28 18:13:30,347 : INFO : min_count=2 retains 24523 unique words (49% of original 49788, drops 25265)\n",
      "2019-05-28 18:13:30,348 : INFO : min_count=2 leaves 2709577 word corpus (99% of original 2734842, drops 25265)\n",
      "2019-05-28 18:13:30,423 : INFO : deleting the raw counts dictionary of 49788 items\n",
      "2019-05-28 18:13:30,425 : INFO : sample=0.001 downsamples 64 most-common words\n",
      "2019-05-28 18:13:30,426 : INFO : downsampling leaves estimated 1852547 word corpus (68.4% of prior 2709577)\n",
      "2019-05-28 18:13:30,487 : INFO : estimated required memory for 24523 words and 100 dimensions: 31879900 bytes\n",
      "2019-05-28 18:13:30,488 : INFO : resetting layer weights\n",
      "2019-05-28 18:13:30,723 : INFO : training model with 8 workers on 24523 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-05-28 18:13:31,741 : INFO : EPOCH 1 - PROGRESS: at 77.49% examples, 1469274 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:31,968 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:31,971 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:31,973 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:31,977 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:31,980 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:31,983 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:31,985 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:31,987 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:31,987 : INFO : EPOCH - 1 : training on 2734842 raw words (1852554 effective words) took 1.3s, 1479362 effective words/s\n",
      "2019-05-28 18:13:33,005 : INFO : EPOCH 2 - PROGRESS: at 75.66% examples, 1438539 words/s, in_qsize 12, out_qsize 3\n",
      "2019-05-28 18:13:33,238 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:33,240 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:33,248 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:33,250 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:33,252 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:33,253 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:33,258 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:33,260 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:33,260 : INFO : EPOCH - 2 : training on 2734842 raw words (1852334 effective words) took 1.3s, 1468306 effective words/s\n",
      "2019-05-28 18:13:34,281 : INFO : EPOCH 3 - PROGRESS: at 76.39% examples, 1444834 words/s, in_qsize 14, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:13:34,514 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:34,517 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:34,518 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:34,518 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:34,519 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:34,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:34,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:34,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:34,526 : INFO : EPOCH - 3 : training on 2734842 raw words (1851294 effective words) took 1.3s, 1475503 effective words/s\n",
      "2019-05-28 18:13:35,544 : INFO : EPOCH 4 - PROGRESS: at 76.39% examples, 1450851 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-28 18:13:35,780 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:35,782 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:35,792 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:35,793 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:35,795 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:35,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:35,798 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:35,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:35,800 : INFO : EPOCH - 4 : training on 2734842 raw words (1852141 effective words) took 1.3s, 1466769 effective words/s\n",
      "2019-05-28 18:13:36,815 : INFO : EPOCH 5 - PROGRESS: at 76.76% examples, 1460303 words/s, in_qsize 16, out_qsize 0\n",
      "2019-05-28 18:13:37,053 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-28 18:13:37,056 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-28 18:13:37,057 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-28 18:13:37,058 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-28 18:13:37,059 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-28 18:13:37,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-28 18:13:37,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-28 18:13:37,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-28 18:13:37,066 : INFO : EPOCH - 5 : training on 2734842 raw words (1852675 effective words) took 1.3s, 1476773 effective words/s\n",
      "2019-05-28 18:13:37,067 : INFO : training on a 13674210 raw words (9260998 effective words) took 6.3s, 1460048 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# Build and save models - by default the Word2Vec runs 5 epochs. We can do more by subsequently\n",
    "# running model.train, or we can just change the default\n",
    "\n",
    "female_model = gensim.models.Word2Vec(female_text, size=100, window=5, min_count=2, workers=8)\n",
    "male_model = gensim.models.Word2Vec(male_text, size=100, window=5, min_count=2, workers=8)\n",
    "movie_model = gensim.models.Word2Vec(movie_text, size=100, window=5, min_count=2, workers=8)\n",
    "lyrics_model = gensim.models.Word2Vec(lyrics_text, size=100, window=5, min_count=2, workers=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:15:16,301 : INFO : saving Word2Vec object under ../Data/female_model.model, separately None\n",
      "2019-05-28 18:15:16,302 : INFO : not storing attribute vectors_norm\n",
      "2019-05-28 18:15:16,303 : INFO : not storing attribute cum_table\n",
      "2019-05-28 18:15:16,304 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-28 18:15:16,642 : INFO : saved ../Data/female_model.model\n",
      "2019-05-28 18:15:16,643 : INFO : saving Word2Vec object under ../Data/male_model.model, separately None\n",
      "2019-05-28 18:15:16,644 : INFO : not storing attribute vectors_norm\n",
      "2019-05-28 18:15:16,644 : INFO : not storing attribute cum_table\n",
      "2019-05-28 18:15:16,645 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-28 18:15:17,311 : INFO : saved ../Data/male_model.model\n",
      "2019-05-28 18:15:17,312 : INFO : saving Word2Vec object under ../Data/movie_model.model, separately None\n",
      "2019-05-28 18:15:17,313 : INFO : not storing attribute vectors_norm\n",
      "2019-05-28 18:15:17,314 : INFO : not storing attribute cum_table\n",
      "2019-05-28 18:15:17,314 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-28 18:15:18,173 : INFO : saved ../Data/movie_model.model\n",
      "2019-05-28 18:15:18,174 : INFO : saving Word2Vec object under ../Data/lyrics_model.model, separately None\n",
      "2019-05-28 18:15:18,175 : INFO : not storing attribute vectors_norm\n",
      "2019-05-28 18:15:18,176 : INFO : not storing attribute cum_table\n",
      "2019-05-28 18:15:18,177 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-28 18:15:18,491 : INFO : saved ../Data/lyrics_model.model\n"
     ]
    }
   ],
   "source": [
    "female_model.save('../Data/female_model.model')\n",
    "male_model.save('../Data/male_model.model')\n",
    "movie_model.save('../Data/movie_model.model')\n",
    "lyrics_model.save('../Data/lyrics_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that models are saved, we can load them later using ```model = Word2Vec.load('../Data/female_model.model')```  \n",
    "or, if we only need the vectors, ```vectors = KeyedVectors.load('../Data/female_model.wv', mmap='r')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:49:07,899 : INFO : saving Word2VecKeyedVectors object under ../Data/female_model.wv, separately None\n",
      "2019-05-28 18:49:07,901 : INFO : not storing attribute vectors_norm\n",
      "2019-05-28 18:49:07,902 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-28 18:49:08,180 : INFO : saved ../Data/female_model.wv\n",
      "2019-05-28 18:49:08,181 : INFO : saving Word2VecKeyedVectors object under ../Data/male_model.wv, separately None\n",
      "2019-05-28 18:49:08,182 : INFO : not storing attribute vectors_norm\n",
      "2019-05-28 18:49:08,182 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-28 18:49:08,639 : INFO : saved ../Data/male_model.wv\n",
      "2019-05-28 18:49:08,640 : INFO : saving Word2VecKeyedVectors object under ../Data/movie_model.wv, separately None\n",
      "2019-05-28 18:49:08,641 : INFO : not storing attribute vectors_norm\n",
      "2019-05-28 18:49:08,642 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-28 18:49:09,359 : INFO : saved ../Data/movie_model.wv\n",
      "2019-05-28 18:49:09,360 : INFO : saving Word2VecKeyedVectors object under ../Data/lyrics_model.wv, separately None\n",
      "2019-05-28 18:49:09,360 : INFO : not storing attribute vectors_norm\n",
      "2019-05-28 18:49:09,362 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-28 18:49:09,600 : INFO : saved ../Data/lyrics_model.wv\n"
     ]
    }
   ],
   "source": [
    "# Also save the vectors only (to improve load time and memory usage if further training is not required)\n",
    "\n",
    "female_model.wv.save('../Data/female_model.wv')\n",
    "male_model.wv.save('../Data/male_model.wv')\n",
    "movie_model.wv.save('../Data/movie_model.wv')\n",
    "lyrics_model.wv.save('../Data/lyrics_model.wv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

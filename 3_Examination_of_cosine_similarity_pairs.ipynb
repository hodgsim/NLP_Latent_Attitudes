{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between datasets\n",
    "### Part one:    Cosine similarity pairs  \n",
    "  \n",
    "In this analysis, we'll explore the cosine similarity between pairs of words, based upon their vector embeddings. Specifically, we will try to identify pairs of words whose use in one dataset implies a degree of similarity that is not reflected in another dataset, to see whether that reveals an implicit bias. For example, if the vector representations of the words \"strawberry\" and \"delicious\" had a much higher cosine similarity in the works of author A than for author B, it would probably indicate that A has a preference for strawberries that is not shared by B.  \n",
    "  \n",
    "This is a prelude to the more rigorous WEAT (Word Embedding Association Test) that will follow, and is designed to check for interesting associations, without the need to rely upon pre-defined lists of emotive words.  \n",
    "  \n",
    "The first step is to find a set of reasonably frequent words that are common across all datasets. Once we have a common set, we can calculate a pairwise cosine similarity matrix for each dataset. Finally, we can compare across these matrices to identify significant outliers, meaning pairs of words that have a strong association in one dataset but not another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding vectors that were just calculated\n",
    "female_vectors = KeyedVectors.load('../Data/female_model.wv', mmap='r')\n",
    "male_vectors = KeyedVectors.load('../Data/male_model.wv', mmap='r')\n",
    "movie_vectors = KeyedVectors.load('../Data/movie_model.wv', mmap='r')\n",
    "lyrics_vectors = KeyedVectors.load('../Data/lyrics_model.wv', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words that are common to all four datasets, taken from the 2500 most frequent words, excluding stop words\n",
    "# In gensim, use model.wv.index2entity[:] to list the vocab in order of frequency\n",
    "stop_words = set(stopwords.words('english'))\n",
    "overlap1 = [word for word in list(female_vectors.index2entity[:2500]) \n",
    "            if word not in stop_words\n",
    "            if word in list(male_vectors.index2entity[:2500])]\n",
    "overlap2 = [word for word in overlap1 if word in list(movie_vectors.index2entity[:2500])]\n",
    "overlap = [word for word in overlap2 if word in list(lyrics_vectors.index2entity[:2500])]\n",
    "\n",
    "len(overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By capping the vocabulary to include only the most frequent words, we are left with a set that can be used to generate a cosine similarity matrix of reasonable size containing words that occur with sufficient frequency to determine their context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>2500th word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>female_vectors</td>\n",
       "      <td>gathering</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>male_vectors</td>\n",
       "      <td>gazing</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>movie_vectors</td>\n",
       "      <td>plans</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>lyrics_vectors</td>\n",
       "      <td>studio</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset 2500th word  Frequency\n",
       "  female_vectors   gathering        131\n",
       "    male_vectors      gazing        158\n",
       "   movie_vectors       plans        374\n",
       "  lyrics_vectors      studio         49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the least frequent word in the truncated dataset, to get a sense of whether it is\n",
    "# particularly unusual (which would indicate that we should select from fewer words)\n",
    "vector_sets = ['female_vectors', 'male_vectors', 'movie_vectors', 'lyrics_vectors']\n",
    "last_words = []\n",
    "frequencies = []\n",
    "\n",
    "for vset in vector_sets:\n",
    "    # need to use globals() to ensure vset refers to the variable x_vectors and not the string 'x_vectors'\n",
    "    last_word = globals()[vset].index2entity[2499]\n",
    "    freq = globals()[vset].vocab[last_word].count\n",
    "    last_words.append(last_word)\n",
    "    frequencies.append(freq)\n",
    "    \n",
    "df=pd.DataFrame(list(zip(vector_sets, last_words, frequencies)), columns=['Dataset','2500th word', 'Frequency'])\n",
    "# don't display index of df\n",
    "blank = ['']*len(df)\n",
    "df.index=blank\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a pairwise cosine similarity matrix between all words in the overlapping set, using the embeddings for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cosine_similarity_matrix(dataset, overlap):\n",
    "    \"\"\"Create a cosine similarity matrix\n",
    "    Args:\n",
    "        dataset: (KeyedVectors object) matrix of vector embeddings generated using gensim word2vec\n",
    "        overlap: list of words for which cosine similarity should be calculated for all possible\n",
    "                word pairs\n",
    "    Returns: (Pandas dataframe) cosine similarity matrix where words form the row and column indices\"\"\"\n",
    "    \n",
    "    # Calculate a list of all cos sim pairs\n",
    "    flat_vals = [dataset.similarity(a,b) for a in overlap for b in overlap]\n",
    "    # reshape to a square matrix\n",
    "    matrix = np.array(flat_vals).reshape(len(overlap), len(overlap))\n",
    "    # turn it into a dataframe\n",
    "    df = pd.DataFrame(matrix, index=overlap, columns=overlap)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the matrices\n",
    "female_cos_sim = build_cosine_similarity_matrix(female_vectors, overlap)\n",
    "male_cos_sim = build_cosine_similarity_matrix(male_vectors, overlap)\n",
    "movie_cos_sim = build_cosine_similarity_matrix(movie_vectors, overlap)\n",
    "lyrics_cos_sim = build_cosine_similarity_matrix(lyrics_vectors, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>said</th>\n",
       "      <th>would</th>\n",
       "      <th>one</th>\n",
       "      <th>mr</th>\n",
       "      <th>could</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093464</td>\n",
       "      <td>0.048281</td>\n",
       "      <td>0.144002</td>\n",
       "      <td>0.093903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.093464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024958</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.715159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.048281</td>\n",
       "      <td>-0.024958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140435</td>\n",
       "      <td>0.034920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr</th>\n",
       "      <td>0.144002</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.140435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>0.093903</td>\n",
       "      <td>0.715159</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>-0.042718</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           said     would       one        mr     could\n",
       "said   1.000000  0.093464  0.048281  0.144002  0.093903\n",
       "would  0.093464  1.000000 -0.024958  0.010740  0.715159\n",
       "one    0.048281 -0.024958  1.000000  0.140435  0.034920\n",
       "mr     0.144002  0.010740  0.140435  1.000000 -0.042718\n",
       "could  0.093903  0.715159  0.034920 -0.042718  1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the top left corner\n",
    "female_cos_sim.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each matrix shows the similarity between all pairings of words. For example, the matrix above shows that based upon the way that female authors use words (revealed by the vector embeddings), \"would\" and \"mister\" have a similarity of 1%, whereas \"would\" and \"could\" have a similarity of 71%. This means that the author uses \"would\" and \"could\" in similar contexts, and therefore has a view about the relationship between them.   \n",
    "  \n",
    "Of course, this is a trivial example and most people would share the author's view in this case. However, it becomes interesting where we see high scores for pairings that are not so syntactically similar, and where the relationship is not present in the works of other authors.  Now that we have consistent matrices for all four datasets, we can search for these types of pairings simply by subtracting one matrix from another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare female authors to male authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_minus_male = female_cos_sim - male_cos_sim\n",
    "# Search for cases where the difference in cosine similarity is greater than 0.5\n",
    "f_higher_m = female_minus_male[female_minus_male>0.5]\n",
    "f_lower_m = female_minus_male[female_minus_male<-0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life     lot       0.556914\n",
      "         double    0.565528\n",
      "make     judge     0.555753\n",
      "love     blind     0.518900\n",
      "new      double    0.643037\n",
      "sense    double    0.649412\n",
      "hear     suit      0.560899\n",
      "certain  double    0.547764\n",
      "keep     judge     0.524804\n",
      "self     double    0.622472\n",
      "change   double    0.547842\n",
      "rose     book      0.512944\n",
      "         paper     0.570109\n",
      "power    lot       0.520135\n",
      "         double    0.581184\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('life', 'lot'),\n",
       " ('life', 'double'),\n",
       " ('make', 'judge'),\n",
       " ('love', 'blind'),\n",
       " ('new', 'double')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all columns or rows that include only NaN values (ie where the difference is less than 0.5)\n",
    "df_reduced = f_higher_m.dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "\n",
    "# This leaves a fairly sparse dataframe, from which we need to extract the row and column headings\n",
    "# for non-Nan values. We set the df up so that the word pairings that we are interested in were used as\n",
    "# the indices, so we can use df.stack() to pivot the data and create a single, multi-level index.\n",
    "# We can then use .items() to loop through each line and collect a tuple of the index (which is now \n",
    "# itself a word-pair tuple) and the difference score\n",
    "\n",
    "# See how the stack() looks\n",
    "print(df_reduced.stack(dropna=True)[:15])\n",
    "\n",
    "# create an iterable of form ((word a, word b), difference score)\n",
    "word_pairs = df_reduced.stack(dropna=True).items()\n",
    "\n",
    "# word_pairs is a zip object, so we can only iterate through it once\n",
    "large_differences = []\n",
    "for item in word_pairs:\n",
    "    large_differences.append(item[0])\n",
    "    \n",
    "# Check that we've properly collected the word-pair tuples\n",
    "large_differences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['life', 'lot']\n",
      "['double', 'life']\n",
      "['judge', 'make']\n",
      "['blind', 'love']\n",
      "['double', 'new']\n",
      "['double', 'sense']\n",
      "['hear', 'suit']\n",
      "['certain', 'double']\n",
      "['judge', 'keep']\n",
      "['double', 'self']\n",
      "['change', 'double']\n",
      "['book', 'rose']\n",
      "['paper', 'rose']\n",
      "['lot', 'power']\n",
      "['double', 'power']\n",
      "['book', 'rose']\n",
      "['book', 'horses']\n",
      "['book', 'singing']\n",
      "['book', 'voices']\n",
      "['book', 'loose']\n",
      "['big', 'pretty']\n",
      "['hair', 'p']\n",
      "['death', 'double']\n",
      "['suit', 'understand']\n",
      "['double', 'fear']\n",
      "['de', 'younger']\n",
      "['says', 'war']\n",
      "['party', 'rain']\n",
      "['party', 'singing']\n",
      "['party', 'wet']\n",
      "['ball', 'party']\n",
      "['double', 'future']\n",
      "['judge', 'show']\n",
      "['page', 'sound']\n",
      "['judge', 'seem']\n",
      "['baby', 'water']\n",
      "['beauty', 'lot']\n",
      "['double', 'real']\n",
      "['lot', 'position']\n",
      "['em', 'war']\n",
      "['green', 'later']\n",
      "['lot', 'strength']\n",
      "['cause', 'double']\n",
      "['carry', 'judge']\n",
      "['double', 'perfect']\n",
      "['finally', 'stone']\n",
      "['imagine', 'judge']\n",
      "['lot', 'memory']\n",
      "['double', 'memory']\n",
      "['force', 'lot']\n",
      "['blood', 'station']\n",
      "['evil', 'lot']\n",
      "['double', 'history']\n",
      "['double', 'private']\n",
      "['paper', 'rose']\n",
      "['f', 'loose']\n",
      "['lot', 'situation']\n",
      "['double', 'situation']\n",
      "['ball', 'situation']\n",
      "['hotel', 'wide']\n",
      "['double', 'serious']\n",
      "['everywhere', 'lord']\n",
      "['page', 'wind']\n",
      "['follow', 'suit']\n",
      "['forget', 'suit']\n",
      "['action', 'lot']\n",
      "['action', 'double']\n",
      "['page', 'touch']\n",
      "['life', 'lot']\n",
      "['lot', 'power']\n",
      "['beauty', 'lot']\n",
      "['lot', 'position']\n",
      "['lot', 'strength']\n",
      "['lot', 'memory']\n",
      "['force', 'lot']\n",
      "['evil', 'lot']\n",
      "['lot', 'situation']\n",
      "['action', 'lot']\n",
      "['lot', 'tongue']\n",
      "['lot', 'peace']\n",
      "['lot', 'system']\n",
      "['blind', 'learn']\n",
      "['learn', 'suit']\n",
      "['brown', 'river']\n",
      "['flowers', 'hotel']\n",
      "['c', 'loose']\n",
      "['lot', 'tongue']\n",
      "['party', 'rain']\n",
      "['cross', 'finally']\n",
      "['brown', 'river']\n",
      "['pair', 'river']\n",
      "['complete', 'double']\n",
      "['eh', 'war']\n",
      "['lot', 'peace']\n",
      "['double', 'peace']\n",
      "['judge', 'make']\n",
      "['judge', 'keep']\n",
      "['judge', 'show']\n",
      "['judge', 'seem']\n",
      "['carry', 'judge']\n",
      "['imagine', 'judge']\n",
      "['eat', 'judge']\n",
      "['judge', 'wear']\n",
      "['judge', 'suit']\n",
      "['buy', 'judge']\n",
      "['judge', 'loose']\n",
      "['judge', 'raise']\n",
      "['double', 'dream']\n",
      "['nice', 'war']\n",
      "['hate', 'suit']\n",
      "['city', 'knife']\n",
      "['grace', 'slow']\n",
      "['page', 'sound']\n",
      "['page', 'wind']\n",
      "['page', 'touch']\n",
      "['loose', 'page']\n",
      "['laughter', 'page']\n",
      "['eat', 'judge']\n",
      "['green', 'later']\n",
      "['horses', 'king']\n",
      "['eight', 'king']\n",
      "['fifty', 'king']\n",
      "['king', 'nine']\n",
      "['couple', 'king']\n",
      "['bought', 'king']\n",
      "['grace', 'slow']\n",
      "['double', 'grace']\n",
      "['blind', 'love']\n",
      "['blind', 'learn']\n",
      "['class', 'singing']\n",
      "['class', 'double']\n",
      "['class', 'couple']\n",
      "['class', 'song']\n",
      "['judge', 'wear']\n",
      "['book', 'horses']\n",
      "['horses', 'king']\n",
      "['horses', 'post']\n",
      "['book', 'singing']\n",
      "['party', 'singing']\n",
      "['class', 'singing']\n",
      "['hotel', 'thick']\n",
      "['explain', 'suit']\n",
      "['hear', 'suit']\n",
      "['suit', 'understand']\n",
      "['follow', 'suit']\n",
      "['forget', 'suit']\n",
      "['learn', 'suit']\n",
      "['judge', 'suit']\n",
      "['hate', 'suit']\n",
      "['explain', 'suit']\n",
      "['sing', 'suit']\n",
      "['de', 'younger']\n",
      "['eight', 'king']\n",
      "['says', 'war']\n",
      "['em', 'war']\n",
      "['eh', 'war']\n",
      "['nice', 'war']\n",
      "['big', 'war']\n",
      "['baby', 'water']\n",
      "['baby', 'square']\n",
      "['check', 'sounds']\n",
      "['double', 'escape']\n",
      "['finally', 'silver']\n",
      "['dry', 'north']\n",
      "['dry', 'p']\n",
      "['dry', 'west']\n",
      "['dry', 'hotel']\n",
      "['bill', 'streets']\n",
      "['double', 'special']\n",
      "['horses', 'post']\n",
      "['baby', 'square']\n",
      "['big', 'pretty']\n",
      "['big', 'war']\n",
      "['buy', 'judge']\n",
      "['pair', 'river']\n",
      "['alive', 'witness']\n",
      "['book', 'voices']\n",
      "['hotel', 'voices']\n",
      "['sing', 'suit']\n",
      "['double', 'life']\n",
      "['double', 'new']\n",
      "['double', 'sense']\n",
      "['certain', 'double']\n",
      "['double', 'self']\n",
      "['change', 'double']\n",
      "['double', 'power']\n",
      "['death', 'double']\n",
      "['double', 'fear']\n",
      "['double', 'future']\n",
      "['double', 'real']\n",
      "['cause', 'double']\n",
      "['double', 'perfect']\n",
      "['double', 'memory']\n",
      "['double', 'history']\n",
      "['double', 'private']\n",
      "['double', 'situation']\n",
      "['double', 'serious']\n",
      "['action', 'double']\n",
      "['complete', 'double']\n",
      "['double', 'peace']\n",
      "['double', 'dream']\n",
      "['double', 'grace']\n",
      "['class', 'double']\n",
      "['double', 'escape']\n",
      "['double', 'special']\n",
      "['double', 'race']\n",
      "['double', 'witness']\n",
      "['double', 'system']\n",
      "['control', 'double']\n",
      "['l', 'la']\n",
      "['hungry', 'la']\n",
      "['fifty', 'king']\n",
      "['anyone', 'heat']\n",
      "['party', 'wet']\n",
      "['p', 'wet']\n",
      "['clean', 'north']\n",
      "['clean', 'west']\n",
      "['king', 'nine']\n",
      "['dry', 'north']\n",
      "['clean', 'north']\n",
      "['knife', 'north']\n",
      "['bill', 'noise']\n",
      "['check', 'sounds']\n",
      "['hotel', 'sounds']\n",
      "['ball', 'party']\n",
      "['ball', 'situation']\n",
      "['couple', 'king']\n",
      "['class', 'couple']\n",
      "['double', 'race']\n",
      "['race', 'turns']\n",
      "['bought', 'king']\n",
      "['b', 'loose']\n",
      "['finally', 'stone']\n",
      "['cross', 'finally']\n",
      "['finally', 'silver']\n",
      "['finally', 'level']\n",
      "['l', 'la']\n",
      "['l', 'loose']\n",
      "['finally', 'level']\n",
      "['alive', 'witness']\n",
      "['double', 'witness']\n",
      "['raise', 'witness']\n",
      "['book', 'loose']\n",
      "['f', 'loose']\n",
      "['c', 'loose']\n",
      "['judge', 'loose']\n",
      "['loose', 'page']\n",
      "['b', 'loose']\n",
      "['l', 'loose']\n",
      "['loose', 'p']\n",
      "['judge', 'raise']\n",
      "['raise', 'witness']\n",
      "['hair', 'p']\n",
      "['dry', 'p']\n",
      "['p', 'wet']\n",
      "['loose', 'p']\n",
      "['lot', 'system']\n",
      "['double', 'system']\n",
      "['class', 'song']\n",
      "['dry', 'west']\n",
      "['clean', 'west']\n",
      "['knife', 'west']\n",
      "['race', 'turns']\n",
      "['anyone', 'heat']\n",
      "['heat', 'hotel']\n",
      "['control', 'double']\n",
      "['laughter', 'page']\n",
      "['bill', 'laughter']\n",
      "['hotel', 'laughter']\n",
      "['bill', 'streets']\n",
      "['bill', 'noise']\n",
      "['bill', 'laughter']\n",
      "['hungry', 'la']\n",
      "['everywhere', 'lord']\n",
      "['blood', 'station']\n",
      "['city', 'knife']\n",
      "['knife', 'north']\n",
      "['knife', 'west']\n",
      "['hotel', 'wide']\n",
      "['flowers', 'hotel']\n",
      "['hotel', 'thick']\n",
      "['dry', 'hotel']\n",
      "['hotel', 'voices']\n",
      "['hotel', 'sounds']\n",
      "['heat', 'hotel']\n",
      "['hotel', 'laughter']\n"
     ]
    }
   ],
   "source": [
    "for t in large_differences:\n",
    "    print(sorted(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dry', 'west'),\n",
       " ('judge', 'suit'),\n",
       " ('lot', 'memory'),\n",
       " ('imagine', 'judge'),\n",
       " ('l', 'la'),\n",
       " ('lot', 'situation'),\n",
       " ('life', 'lot'),\n",
       " ('judge', 'show'),\n",
       " ('follow', 'suit')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ordering in the tuples doesn't actually matter, since cosine similarity is commutative\n",
    "# ie cos_sim(a,b) = cos_sim(b,a), so we can simplify the list by removing duplicates once we ignore\n",
    "# ordering. If we loop through the tuples t and apply sorted(t) it will return sorted lists. We can then\n",
    "# create a tuple of all the lists and apply set() to get the unique items (remember lists are mutable and\n",
    "# so we can't apply set() to them)\n",
    "large_differences_unique = set(tuple(sorted(t)) for t in large_differences)\n",
    "\n",
    "# Now, let's look at the pairs that exhibit significant similarity in one dataset only.\n",
    "\n",
    "sig_diff = []\n",
    "for item in large_differences_unique:\n",
    "    if female_cos_sim.loc[item[0],item[1]]>0.7:\n",
    "        sig_diff.append(item)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "sig_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without further context it is difficult to assess the meaning behind the stronger association between these pairs in the works of female authors, but it is possible that \"lot\" is being used in the sense of a predetermined condition or situation, ie their 'lot in life'. If so, it would be interesting that this is a frequent enough topic that the words only become associated in books by female authors, and may suggest that male authors speak about their characters less in terms of destiny or social position. Having said that, there is a risk of projecting bias when interpreting data and more work would have to be done to understand the true contextual meaning of those bigrams. There are no instances in the male corpus where the cosine similarity between a pair of words is higher than 0.7 and more than 0.5 higher than the same pair in the female corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've worked out the code, create a function to recycle it\n",
    "\n",
    "def find_interesting_pairs(dataframe_a, dataframe_b, min_difference=0.5, starting_threshold=0.7):\n",
    "    \"\"\"Finds significant differences between two cosine similarity matrices of the same size\n",
    "       that were built using the same vocabulary\n",
    "       \n",
    "       Args:\n",
    "           dataframe_a, _b: the two cosine similarity matrices to compare\n",
    "           min_difference: threshold by which the similarity in one dataset should exceed the other\n",
    "           starting_threshold: only pairings that exceed this threshold in one dataset will be considered\n",
    "       Returns:\n",
    "           two lists; word-pair tuples that are significant in dataset a but not b and\n",
    "                      word-pair tuples that are significant in dataset b but not a\"\"\"\n",
    "    \n",
    "    diff = dataframe_a - dataframe_b\n",
    "    a_higher = diff[diff>min_difference]\n",
    "    b_higher = diff[diff<-min_difference]\n",
    "    \n",
    "    differences = []\n",
    "    \n",
    "    for n in [a_higher, b_higher]:\n",
    "        n_reduced = n.dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "        word_pairs = n_reduced.stack(dropna=True).items()\n",
    "        large_differences = []\n",
    "        for item in word_pairs:\n",
    "            large_differences.append(item[0])\n",
    "        large_differences_unique = set(tuple(sorted(t)) for t in large_differences)\n",
    "        sig_diff = []\n",
    "        for item in large_differences_unique:\n",
    "            if n is a_higher:\n",
    "                if dataframe_a.loc[item[0],item[1]]>starting_threshold:\n",
    "                    sig_diff.append(item)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if dataframe_b.loc[item[0],item[1]]>starting_threshold:\n",
    "                    sig_diff.append(item)\n",
    "                else:\n",
    "                    pass\n",
    "        differences.append(sig_diff)\n",
    "        \n",
    "    return differences[0], differences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare authors to movie scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "[('key', 'window'), ('arms', 'heads'), ('flat', 'leaves'), ('beat', 'shake'), ('double', 'stone'), ('rising', 'rose'), ('brown', 'rough'), ('rough', 'yellow'), ('blue', 'leaves'), ('blue', 'rough'), ('red', 'rough'), ('double', 'flat'), ('leaves', 'wet'), ('leaves', 'stone'), ('music', 'wild'), ('leaves', 'sky'), ('places', 'ways'), ('double', 'dry'), ('held', 'kept'), ('leaves', 'trees'), ('grey', 'rough'), ('glass', 'hat'), ('flowers', 'wild'), ('leaves', 'rain'), ('coat', 'glass'), ('leaves', 'wood'), ('gold', 'rough'), ('leaves', 'stream'), ('grass', 'leaves'), ('clouds', 'leaves'), ('flowers', 'lights'), ('leaves', 'thick'), ('box', 'chin'), ('flowers', 'leaves'), ('garden', 'lights'), ('leaves', 'windows'), ('grace', 'respect'), ('bank', 'floor'), ('bow', 'glass'), ('leaves', 'snow'), ('dark', 'leaves'), ('box', 'knee'), ('bear', 'lead'), ('walked', 'walking'), ('dry', 'leaves'), ('face', 'figure'), ('leaves', 'walls'), ('cause', 'situation'), ('leaves', 'tree'), ('ring', 'yard'), ('places', 'streets'), ('fingers', 'heads'), ('bright', 'flowers'), ('bank', 'edge'), ('burning', 'leaves'), ('field', 'lights'), ('brother', 'master'), ('green', 'leaves'), ('leaves', 'yellow'), ('cloud', 'leaves'), ('caught', 'raised')]\n"
     ]
    }
   ],
   "source": [
    "male_higher, movies_higher = find_interesting_pairs(male_cos_sim, \n",
    "                                                    movie_cos_sim,\n",
    "                                                    min_difference=0.5,\n",
    "                                                    starting_threshold=0.7)\n",
    "\n",
    "print(len(male_higher))\n",
    "print(male_higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n",
      "[('garden', 'leaves'), ('grass', 'lights'), ('brown', 'soft'), ('floor', 'steps'), ('leaves', 'sea'), ('silver', 'stars'), ('brown', 'dark'), ('front', 'glass'), ('leaves', 'storm'), ('black', 'nose'), ('flat', 'leaves'), ('bank', 'silver'), ('flat', 'west'), ('doors', 'wind'), ('leaves', 'rough'), ('rain', 'summer'), ('doors', 'river'), ('gold', 'snow'), ('hill', 'wood'), ('tree', 'wide'), ('bank', 'wood'), ('brown', 'glass'), ('doors', 'hill'), ('floor', 'green'), ('clean', 'grass'), ('hill', 'wet'), ('blue', 'leaves'), ('flowers', 'square'), ('building', 'flowers'), ('streets', 'wall'), ('stream', 'wide'), ('breaking', 'turns'), ('lines', 'sounds'), ('ring', 'shoulder'), ('calm', 'quick'), ('black', 'dry'), ('leaves', 'trees'), ('kitchen', 'street'), ('moved', 'rose'), ('bank', 'lights'), ('west', 'wood'), ('flowers', 'heads'), ('page', 'top'), ('path', 'wide'), ('brown', 'trees'), ('leaves', 'thick'), ('bringing', 'leaving'), ('field', 'front'), ('wide', 'wind'), ('doors', 'sea'), ('top', 'windows'), ('eh', 'says'), ('gold', 'shadow'), ('silver', 'trees'), ('lying', 'wall'), ('west', 'wind'), ('silver', 'sky'), ('coat', 'floor'), ('glass', 'river'), ('floor', 'white'), ('silver', 'windows'), ('floor', 'leaves'), ('sun', 'west'), ('gold', 'grass'), ('glass', 'round'), ('heads', 'teeth'), ('position', 'style'), ('dark', 'leaves'), ('fire', 'garden'), ('flat', 'flowers'), ('dry', 'wide'), ('river', 'wide'), ('floor', 'path'), ('garden', 'wood'), ('west', 'wet'), ('lights', 'places'), ('west', 'yellow'), ('moving', 'ran'), ('walked', 'walking'), ('horses', 'steps'), ('judge', 'show'), ('leaves', 'walls'), ('green', 'wall'), ('foot', 'page'), ('flat', 'gold'), ('garden', 'top'), ('broke', 'turns'), ('leaves', 'silver'), ('path', 'spread'), ('corner', 'paper'), ('broke', 'running'), ('flowers', 'roof'), ('stone', 'street'), ('burning', 'leaves'), ('front', 'streets'), ('floor', 'silver'), ('sea', 'silver'), ('hotel', 'stars'), ('change', 'shock'), ('walls', 'west'), ('floor', 'ring'), ('burning', 'wall'), ('foot', 'paper'), ('clothes', 'heads'), ('brother', 'master'), ('silver', 'water'), ('fire', 'wall'), ('green', 'leaves'), ('boat', 'paper'), ('hotel', 'sun'), ('rose', 'started'), ('cloud', 'rough'), ('lights', 'spread'), ('bright', 'leaves'), ('doors', 'street'), ('crowd', 'stars'), ('dry', 'lights'), ('clean', 'flat'), ('brown', 'flat'), ('spread', 'wide'), ('leaves', 'river'), ('black', 'glass'), ('silver', 'wide'), ('leaves', 'shadow'), ('heads', 'pictures'), ('leaves', 'stars'), ('hotel', 'top'), ('rising', 'window'), ('fire', 'glass'), ('moving', 'rose'), ('faces', 'places'), ('box', 'foot'), ('leaves', 'soft'), ('hill', 'silver'), ('falling', 'hill'), ('corner', 'doors'), ('fire', 'window'), ('bank', 'green'), ('coat', 'stick'), ('bank', 'leaves'), ('flat', 'rough'), ('hill', 'spread'), ('leaves', 'pink'), ('lights', 'west'), ('brown', 'snow'), ('blue', 'wall'), ('gold', 'trees'), ('leaves', 'red'), ('flowers', 'stream'), ('garden', 'silver'), ('rising', 'straight'), ('blue', 'rough'), ('hanging', 'turns'), ('front', 'river'), ('building', 'leaves'), ('hill', 'thick'), ('clouds', 'flowers'), ('leaves', 'sky'), ('field', 'leaves'), ('names', 'places'), ('edge', 'leaves'), ('clouds', 'summer'), ('rough', 'tree'), ('guess', 'judge'), ('corner', 'top'), ('brown', 'sky'), ('lying', 'river'), ('leaves', 'wood'), ('spread', 'wind'), ('clouds', 'leaves'), ('flowers', 'lights'), ('heads', 'places'), ('brown', 'leaves'), ('flowers', 'wide'), ('clean', 'dark'), ('started', 'turned'), ('heads', 'legs'), ('floor', 'thick'), ('birds', 'grey'), ('lights', 'square'), ('leaves', 'windows'), ('follow', 'suit'), ('flowers', 'voices'), ('lights', 'stream'), ('broke', 'throwing'), ('lights', 'rough'), ('birds', 'leaves'), ('roof', 'silver'), ('corner', 'straight'), ('heat', 'leaves'), ('stars', 'west'), ('darkness', 'leaves'), ('trees', 'west'), ('heat', 'summer'), ('boat', 'doors'), ('leaves', 'snow'), ('lying', 'silver'), ('green', 'hill'), ('burning', 'flowers'), ('big', 'fine'), ('stone', 'top'), ('imagine', 'judge'), ('moon', 'wide'), ('head', 'stick'), ('rough', 'silver'), ('snow', 'summer'), ('afternoon', 'stage'), ('front', 'garden'), ('hat', 'straight'), ('river', 'yellow'), ('dark', 'gold'), ('rose', 'suddenly'), ('silver', 'wall'), ('brown', 'water'), ('lights', 'wide'), ('river', 'wall'), ('places', 'streets'), ('gold', 'sky'), ('birds', 'gray'), ('feet', 'heads'), ('brown', 'tree'), ('birds', 'silver'), ('wall', 'wide'), ('field', 'top'), ('heavy', 'leaves'), ('gold', 'leaves'), ('heads', 'names'), ('brown', 'walls'), ('road', 'steps'), ('snow', 'west'), ('river', 'top'), ('dry', 'square'), ('glass', 'square'), ('brown', 'clouds'), ('flat', 'stars'), ('leaves', 'white'), ('steady', 'sweet'), ('clouds', 'gold'), ('clean', 'leaves'), ('glass', 'leaves'), ('feet', 'leaves'), ('red', 'river'), ('hotel', 'moon'), ('cloud', 'leaves'), ('caught', 'raised'), ('finger', 'floor'), ('hill', 'yellow'), ('gold', 'square'), ('river', 'wet'), ('heads', 'voices'), ('bank', 'yellow'), ('ears', 'heads'), ('silver', 'wind'), ('silver', 'stream'), ('dry', 'west'), ('black', 'water'), ('steps', 'stone'), ('kitchen', 'road'), ('gold', 'tree'), ('hotel', 'wood'), ('flowers', 'river'), ('leaves', 'legs'), ('hanging', 'path'), ('stick', 'watch'), ('steps', 'walls'), ('bank', 'stone'), ('middle', 'summer'), ('glass', 'yellow'), ('bank', 'doors'), ('rising', 'rose'), ('front', 'yard'), ('brown', 'rough'), ('river', 'silver'), ('flat', 'white'), ('lot', 'race'), ('lights', 'silver'), ('front', 'street'), ('field', 'silver'), ('floor', 'straight'), ('birds', 'pink'), ('rough', 'yellow'), ('blue', 'glass'), ('birds', 'green'), ('brown', 'square'), ('coat', 'edge'), ('lights', 'river'), ('red', 'rough'), ('feeling', 'shock'), ('water', 'white'), ('leaves', 'wet'), ('lying', 'walls'), ('grass', 'silver'), ('dry', 'sky'), ('field', 'glass'), ('shock', 'sign'), ('front', 'steps'), ('corner', 'glass'), ('ring', 'seat'), ('grey', 'rough'), ('front', 'windows'), ('coat', 'glass'), ('gray', 'leaves'), ('gold', 'rough'), ('rough', 'white'), ('bank', 'foot'), ('grass', 'leaves'), ('gold', 'walls'), ('leaves', 'top'), ('cause', 'power'), ('moving', 'walked'), ('flat', 'yellow'), ('leaves', 'moon'), ('doors', 'front'), ('clean', 'tree'), ('clean', 'red'), ('building', 'silver'), ('bank', 'steps'), ('tree', 'west'), ('falling', 'yellow'), ('building', 'middle'), ('bank', 'lying'), ('box', 'horse'), ('doors', 'garden'), ('cloud', 'gold'), ('straight', 'thick'), ('bank', 'floor'), ('beneath', 'leaves'), ('fire', 'path'), ('broke', 'shut'), ('lying', 'wood'), ('glass', 'straight'), ('boat', 'hotel'), ('thick', 'west'), ('silver', 'walls'), ('pictures', 'places'), ('hill', 'lying'), ('birds', 'flat'), ('silver', 'snow'), ('lying', 'square'), ('hanging', 'leaves'), ('sky', 'wild'), ('brown', 'legs'), ('thinks', 'wants'), ('cool', 'quick'), ('leaves', 'streets'), ('shop', 'stone'), ('stars', 'wall'), ('hill', 'kitchen'), ('black', 'leaves'), ('flat', 'grey'), ('ring', 'watch'), ('dry', 'leaves'), ('hat', 'seat'), ('bird', 'flat'), ('judge', 'learn'), ('black', 'neck'), ('leaves', 'tree'), ('black', 'clean'), ('gold', 'stream'), ('judge', 'suit'), ('leaves', 'path'), ('bright', 'flowers'), ('leaves', 'square'), ('line', 'paper'), ('red', 'water'), ('bank', 'snow'), ('grey', 'soft'), ('clean', 'thin'), ('leaves', 'water'), ('crowd', 'lights'), ('crowd', 'wood'), ('flowers', 'rough'), ('floor', 'stick'), ('doors', 'sun'), ('leaves', 'lines'), ('gold', 'water'), ('doors', 'moon'), ('leaves', 'lying'), ('silver', 'tree'), ('stopped', 'watching'), ('bird', 'walls'), ('boat', 'box'), ('blue', 'water'), ('knee', 'watch'), ('water', 'yellow'), ('front', 'leaves'), ('burning', 'rough'), ('beat', 'shake'), ('river', 'wood'), ('lights', 'wood'), ('stream', 'west'), ('field', 'page'), ('green', 'water'), ('leaves', 'wide'), ('bird', 'line'), ('summer', 'wet'), ('hill', 'walls'), ('leaves', 'wind'), ('hanging', 'hill'), ('clean', 'white'), ('glass', 'white'), ('flowers', 'light'), ('class', 'race'), ('gold', 'river'), ('ran', 'stopped'), ('leaves', 'thin'), ('boat', 'steps'), ('show', 'suit'), ('hill', 'leaves'), ('leaves', 'stone'), ('green', 'wind'), ('idea', 'shock'), ('held', 'kept'), ('edge', 'fire'), ('dry', 'stars'), ('top', 'yard'), ('flat', 'silver'), ('red', 'wall'), ('flowers', 'wild'), ('brown', 'stream'), ('leaves', 'rain'), ('square', 'yellow'), ('dry', 'hill'), ('leaves', 'pair'), ('leaves', 'lights'), ('leaves', 'stream'), ('summer', 'wind'), ('clean', 'stream'), ('coat', 'path'), ('lights', 'thick'), ('leaves', 'wall'), ('clean', 'trees'), ('brown', 'cloud'), ('flowers', 'leaves'), ('lights', 'sea'), ('closed', 'watching'), ('pink', 'square'), ('floor', 'hill'), ('leaves', 'sun'), ('clouds', 'silver'), ('ran', 'turning'), ('floor', 'yellow'), ('garden', 'lights'), ('flowers', 'sky'), ('flowers', 'soft'), ('lives', 'places'), ('birds', 'red'), ('foot', 'ring'), ('blue', 'wild'), ('bow', 'laughter'), ('square', 'wind'), ('moon', 'west'), ('silver', 'square'), ('ran', 'stairs'), ('burning', 'west'), ('flowers', 'red'), ('lights', 'white'), ('hat', 'slowly'), ('flowers', 'shadow'), ('lights', 'moon'), ('front', 'wood'), ('building', 'gold'), ('box', 'knee'), ('box', 'stick'), ('ring', 'table'), ('legs', 'silver'), ('bank', 'top'), ('sky', 'spread'), ('dark', 'flowers'), ('glass', 'green'), ('sky', 'west'), ('grass', 'west'), ('doors', 'grass'), ('seat', 'stick'), ('falling', 'leaves'), ('ran', 'rose'), ('leaves', 'roof'), ('clean', 'square'), ('birds', 'yellow'), ('judge', 'understand'), ('street', 'wood'), ('grey', 'leaves'), ('floor', 'red'), ('square', 'wet'), ('green', 'west'), ('lights', 'wind'), ('steps', 'top'), ('lights', 'tree'), ('sky', 'wide'), ('gold', 'windows'), ('lot', 'memory'), ('glass', 'gold'), ('doors', 'road'), ('blue', 'flowers'), ('doors', 'stars'), ('bank', 'grass'), ('clouds', 'west'), ('silver', 'west'), ('falling', 'silver'), ('doors', 'leaves'), ('gold', 'lights'), ('flowers', 'wind'), ('field', 'lights'), ('lying', 'yellow'), ('birds', 'square'), ('path', 'silver'), ('floor', 'gold'), ('ball', 'hotel'), ('leaves', 'spread'), ('glass', 'red'), ('floor', 'stars'), ('gold', 'wall'), ('rose', 'stopped'), ('boat', 'key'), ('leaves', 'yellow'), ('history', 'race'), ('leaves', 'west'), ('brown', 'neck'), ('gray', 'lights')]\n"
     ]
    }
   ],
   "source": [
    "female_higher, movies_higher = find_interesting_pairs(female_cos_sim, \n",
    "                                                    movie_cos_sim,\n",
    "                                                    min_difference=0.5,\n",
    "                                                    starting_threshold=0.7)\n",
    "\n",
    "print(len(female_higher))\n",
    "print(female_higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 'n'),\n",
       " ('knew', 'said'),\n",
       " ('going', 'supposed'),\n",
       " ('coat', 'suit'),\n",
       " ('hat', 'suit'),\n",
       " ('anybody', 'anyone')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are far more pairings containing adjectives in the works of male and female authors than are found in movie scripts. It seems likely that this is because works of literature focus on detailed descriptions and so word pairs involving an adjective and a noun are likely to be closer together in the vector space. Movie scripts focus on dialog and tend to have only brief descriptive passages, therefore the result is perhaps not surprising. One interesting feature though is that while there are 61 word pairs in the male corpus that significantly exceed the similarity of the same pair in the movie corpus, there are 519, or more than eight times as many of these pairs in the female corpus. This may be the result of more expressive language or a broader range of descriptions being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare authors to lyrics  \n",
    "  \n",
    "A similar pattern is observed when the comparison is the lyrics dataset. Again, descriptive pairings are more prevalent in the authors data set, and the pairings in the female dataset outnumber those in the male dataset, this time by five to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "[('red', 'rough'), ('horses', 'together'), ('falling', 'wet'), ('pink', 'rough'), ('floor', 'knee'), ('stone', 'wood'), ('drop', 'fall'), ('dry', 'hot'), ('double', 'dry'), ('arms', 'chin'), ('act', 'action'), ('chin', 'head'), ('floor', 'stone'), ('friend', 'master'), ('gold', 'rough'), ('carry', 'throw'), ('rough', 'white'), ('double', 'stone'), ('black', 'hair'), ('brown', 'rough'), ('hot', 'warm'), ('head', 'knife'), ('burning', 'hot'), ('sky', 'wood'), ('rough', 'silver'), ('black', 'flowers'), ('rain', 'wet'), ('cause', 'meaning'), ('sky', 'wet'), ('rough', 'yellow'), ('black', 'rough'), ('green', 'rough'), ('laughter', 'loud'), ('face', 'figure'), ('holding', 'throwing'), ('fresh', 'wild')]\n"
     ]
    }
   ],
   "source": [
    "male_higher, lyrics_higher = find_interesting_pairs(male_cos_sim, \n",
    "                                                    lyrics_cos_sim,\n",
    "                                                    min_difference=0.5,\n",
    "                                                    starting_threshold=0.7)\n",
    "\n",
    "print(len(male_higher))\n",
    "print(male_higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "[('gold', 'square'), ('stars', 'thick'), ('pink', 'rough'), ('floor', 'steps'), ('dark', 'square'), ('corner', 'square'), ('arms', 'chin'), ('thick', 'wall'), ('thick', 'walls'), ('dark', 'wet'), ('brown', 'dark'), ('floor', 'stone'), ('bank', 'sea'), ('around', 'beneath'), ('bank', 'stone'), ('river', 'wood'), ('red', 'square'), ('floor', 'glass'), ('brown', 'rough'), ('lot', 'race'), ('moon', 'square'), ('lights', 'silver'), ('gold', 'loose'), ('hanging', 'thick'), ('sky', 'square'), ('floor', 'green'), ('floor', 'straight'), ('dry', 'wood'), ('rough', 'yellow'), ('soft', 'wild'), ('black', 'rough'), ('roof', 'square'), ('blue', 'rough'), ('sea', 'wet'), ('red', 'rough'), ('dry', 'hot'), ('la', 'p'), ('c', 'la'), ('square', 'walls'), ('gold', 'rough'), ('rough', 'white'), ('field', 'floor'), ('lights', 'thick'), ('guess', 'imagine'), ('floor', 'foot'), ('lives', 'race'), ('floor', 'thick'), ('river', 'square'), ('lights', 'square'), ('holding', 'throwing'), ('floor', 'yellow'), ('foot', 'ring'), ('burning', 'spread'), ('coat', 'floor'), ('square', 'stars'), ('field', 'rain'), ('floor', 'leaves'), ('flowers', 'red'), ('foot', 'stone'), ('dry', 'red'), ('burning', 'flowers'), ('post', 'shop'), ('front', 'square'), ('loud', 'low'), ('dry', 'green'), ('head', 'stick'), ('stars', 'wet'), ('flat', 'sky'), ('sky', 'wood'), ('rough', 'silver'), ('green', 'square'), ('flat', 'green'), ('burning', 'path'), ('stars', 'wood'), ('shoulder', 'stick'), ('blue', 'flat'), ('dark', 'wood'), ('dry', 'tree'), ('foot', 'stick'), ('lights', 'wide'), ('cool', 'soft'), ('walls', 'wet'), ('everybody', 'everything'), ('bright', 'flowers'), ('sun', 'wet'), ('middle', 'square'), ('black', 'hair'), ('blue', 'flowers'), ('floor', 'silver'), ('hot', 'warm'), ('floor', 'square'), ('l', 'la'), ('sea', 'wood'), ('flat', 'stars'), ('box', 'floor'), ('sun', 'wood'), ('king', 'lord'), ('black', 'flowers'), ('sky', 'wet'), ('floor', 'grass'), ('green', 'rough'), ('brown', 'flat'), ('knife', 'stick'), ('square', 'wall')]\n"
     ]
    }
   ],
   "source": [
    "female_higher, lyrics_higher = find_interesting_pairs(female_cos_sim, \n",
    "                                                    lyrics_cos_sim,\n",
    "                                                    min_difference=0.5,\n",
    "                                                    starting_threshold=0.75)\n",
    "\n",
    "print(len(female_higher))\n",
    "print(female_higher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time though, there are pairings in the lyrics dataset that are more significant than those in the authors datasets (194 vs male authors, and 217 vs female authors). It is difficult to discern any meaning from them though - pairs such as 'coat' and 'position', 'master' and 'shape', and 'dinner' and 'ears' seem somewhat random, although it makes sense that they would not be associated in the authors data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chin', 'john'),\n",
       " ('church', 'state'),\n",
       " ('building', 'raised'),\n",
       " ('pair', 'state'),\n",
       " ('master', 'state'),\n",
       " ('chin', 'p'),\n",
       " ('grey', 'letters'),\n",
       " ('bow', 'p'),\n",
       " ('dinner', 'ears'),\n",
       " ('c', 'john'),\n",
       " ('coat', 'suit'),\n",
       " ('coat', 'john'),\n",
       " ('master', 'weight'),\n",
       " ('history', 'silence'),\n",
       " ('master', 'shape'),\n",
       " ('coat', 'order'),\n",
       " ('grand', 'raised'),\n",
       " ('hungry', 'showing'),\n",
       " ('bow', 'e'),\n",
       " ('coat', 'position'),\n",
       " ('food', 'john'),\n",
       " ('f', 'john'),\n",
       " ('course', 'pair'),\n",
       " ('company', 'note'),\n",
       " ('box', 'john'),\n",
       " ('grand', 'l'),\n",
       " ('e', 'tom'),\n",
       " ('master', 'signs'),\n",
       " ('box', 'suit'),\n",
       " ('bow', 'c'),\n",
       " ('f', 'tom'),\n",
       " ('coat', 'dinner'),\n",
       " ('silence', 'view'),\n",
       " ('business', 'ears'),\n",
       " ('bow', 'john'),\n",
       " ('grey', 'master'),\n",
       " ('chair', 'suit'),\n",
       " ('chin', 'l'),\n",
       " ('distance', 'history'),\n",
       " ('completely', 'using'),\n",
       " ('field', 'master'),\n",
       " ('raised', 'riding'),\n",
       " ('grand', 'john'),\n",
       " ('chin', 'grand'),\n",
       " ('box', 'position'),\n",
       " ('e', 'john'),\n",
       " ('field', 'position'),\n",
       " ('glass', 'memory'),\n",
       " ('raised', 'written'),\n",
       " ('chair', 'system'),\n",
       " ('master', 'pair'),\n",
       " ('position', 'wood'),\n",
       " ('bow', 'l'),\n",
       " ('able', 'listening')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These pairings seem unusual and somewhat random, which raises concerns about the accuracy of the embeddings. However, we've selected only pairs that are highly similar in the lyrics dataset and yet dissimilar in the authors dataset, and only words that are present in all four datasets. There may be other pairings that make sense but that are not included. To check, let's look other similarities in the lyrics database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('faith', 0.6209509968757629),\n",
       " ('life', 0.6110489964485168),\n",
       " ('lovin', 0.5921348333358765),\n",
       " ('part', 0.5828093886375427),\n",
       " ('heart', 0.5781996250152588),\n",
       " ('pride', 0.575323224067688),\n",
       " ('loving', 0.5753142237663269),\n",
       " ('fate', 0.5610586404800415),\n",
       " ('kiss', 0.559472918510437),\n",
       " ('touch', 0.5581563115119934)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_vectors.similar_by_word(\"love\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8071155548095703),\n",
       " ('guy', 0.7773389220237732),\n",
       " ('kid', 0.672675371170044),\n",
       " ('fool', 0.6429462432861328),\n",
       " ('wife', 0.6306154727935791),\n",
       " ('boy', 0.6269347667694092),\n",
       " ('chick', 0.6240472197532654),\n",
       " ('friend', 0.5892120003700256),\n",
       " ('girlfriend', 0.5751911401748657),\n",
       " ('girl', 0.5750477313995361)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_vectors.similar_by_word(\"man\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rhythm', 0.7320751547813416),\n",
       " ('radio', 0.6641572713851929),\n",
       " ('sound', 0.6535687446594238),\n",
       " ('dj', 0.6059355139732361),\n",
       " ('funky', 0.6055202484130859),\n",
       " ('heat', 0.5942786931991577),\n",
       " ('guitar', 0.5870826244354248),\n",
       " ('madness', 0.5857604146003723),\n",
       " ('groove', 0.5843908190727234),\n",
       " ('beat', 0.5765078067779541)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_vectors.similar_by_word(\"music\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, it appears that the embeddings do make sense. Therefore it is more likely that the words in the overlapping set are not as commonly used in the lyrics set (which contains a lot of stylized words and follows looser grammar and spelling rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('john', 9), ('master', 7), ('bow', 5), ('coat', 5), ('chin', 4)]\n",
      "\n",
      "\n",
      "master is ranked 2370 in the lyrics dataset, appearing 54 times\n",
      "john is ranked 1655 in the lyrics dataset, appearing 94 times\n",
      "grand is ranked 1941 in the lyrics dataset, appearing 73 times\n",
      "system is ranked 1662 in the lyrics dataset, appearing 94 times\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# create a list of all words contained in lyrics_higher \n",
    "allwords = []\n",
    "for tup in lyrics_higher:\n",
    "    allwords.append(tup[0])\n",
    "    allwords.append(tup[1])\n",
    "\n",
    "# Use Counter to create a dictionary of the counts of each word\n",
    "counted = Counter(allwords)\n",
    "\n",
    "# Sort the dictionary by value to identify the most frequently occuring words in lyrics higher\n",
    "print(sorted(counted.items(), key = lambda x: x[1], reverse=True)[:5])\n",
    "print('\\n')\n",
    "\n",
    "# Check where they rank in the lyrics dataset\n",
    "for word in ['master', 'john', 'grand', 'system']:\n",
    "    print('{0} is ranked {1} in the lyrics dataset, appearing {2} times'\n",
    "          .format(word, lyrics_vectors.vocab[word].index, lyrics_vectors.vocab[word].count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the unusual words in the lyrics_higher set are actually fairly rare in the lyrics dataset, suggesting that the issue is more with the embeddings of rare words than the embeddings in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare scripts and lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[('pain', 'shock')]\n",
      "364\n",
      "[('box', 'tom'), ('chin', 'sharp'), ('closed', 'smiling'), ('dinner', 'suit'), ('careful', 'post'), ('box', 'master'), ('completely', 'grey'), ('book', 'ears'), ('chin', 'john'), ('hat', 'system'), ('six', 'station'), ('heads', 'teeth'), ('pictures', 'weight'), ('f', 'station'), ('building', 'raised'), ('coat', 'yard'), ('master', 'names'), ('f', 'ugly'), ('grand', 'pink'), ('pair', 'state'), ('grey', 'paper'), ('company', 'wood'), ('company', 'shock'), ('beauty', 'book'), ('chin', 'p'), ('horse', 'table'), ('grey', 'letters'), ('hat', 'windows'), ('judge', 'station'), ('coat', 'stream'), ('bow', 'p'), ('ears', 'heads'), ('dinner', 'ears'), ('shape', 'station'), ('grey', 'silent'), ('riding', 'windows'), ('listening', 'serious'), ('chair', 'dinner'), ('passing', 'written'), ('silent', 'ugly'), ('food', 'sharp'), ('john', 'master'), ('gray', 'leaves'), ('history', 'weight'), ('dying', 'leaving'), ('grand', 'ugly'), ('food', 'shock'), ('c', 'john'), ('age', 'beginning'), ('company', 'position'), ('history', 'pair'), ('p', 'tom'), ('coat', 'john'), ('book', 'path'), ('minutes', 'station'), ('history', 'silence'), ('e', 'fifty'), ('bill', 'master'), ('master', 'shape'), ('coat', 'order'), ('master', 'stream'), ('cloud', 'table'), ('names', 'teeth'), ('book', 'silence'), ('distance', 'land'), ('order', 'shape'), ('dying', 'listening'), ('p', 'pink'), ('flat', 'north'), ('history', 'view'), ('crowd', 'system'), ('master', 'table'), ('building', 'letters'), ('grand', 'raised'), ('completely', 'hearing'), ('alive', 'near'), ('company', 'john'), ('building', 'rising'), ('finger', 'heads'), ('company', 'pair'), ('box', 'ears'), ('distance', 'future'), ('state', 'weight'), ('station', 'table'), ('apart', 'asleep'), ('doors', 'stream'), ('chin', 'e'), ('flat', 'showing'), ('book', 'view'), ('ears', 'pocket'), ('force', 'scene'), ('cup', 'teeth'), ('book', 'field'), ('double', 'l'), ('company', 'shape'), ('horse', 'paper'), ('path', 'pictures'), ('master', 'station'), ('kitchen', 'north'), ('book', 'shadow'), ('building', 'dressed'), ('tom', 'ugly'), ('position', 'stream'), ('hungry', 'showing'), ('master', 'pink'), ('master', 'tom'), ('page', 'path'), ('flat', 'tom'), ('e', 'grand'), ('command', 'ears'), ('bow', 'e'), ('coat', 'system'), ('pictures', 'state'), ('clouds', 'leaves'), ('horse', 'silver'), ('food', 'john'), ('master', 'wood'), ('pair', 'pictures'), ('busy', 'paid'), ('field', 'paper'), ('ears', 'suit'), ('chin', 'pink'), ('fingers', 'heads'), ('company', 'l'), ('building', 'riding'), ('fifty', 'master'), ('angry', 'using'), ('coat', 'master'), ('shaking', 'showing'), ('chin', 'order'), ('f', 'john'), ('l', 'station'), ('table', 'tone'), ('course', 'pair'), ('finally', 'somehow'), ('book', 'weight'), ('chair', 'windows'), ('busy', 'older'), ('business', 'pocket'), ('company', 'note'), ('horse', 'pink'), ('completely', 'ugly'), ('field', 'l'), ('calm', 'shaking'), ('letters', 'raised'), ('grey', 'written'), ('pocket', 'style'), ('chin', 'master'), ('bill', 'l'), ('book', 'cloud'), ('dressed', 'raised'), ('course', 'weight'), ('listening', 'whether'), ('bank', 'chair'), ('dinner', 'nose'), ('box', 'dinner'), ('master', 'note'), ('box', 'john'), ('grand', 'l'), ('john', 'pink'), ('grey', 'signs'), ('e', 'tom'), ('box', 'grand'), ('stories', 'teeth'), ('laughing', 'raised'), ('coat', 'names'), ('c', 'tom'), ('cup', 'neck'), ('bow', 'tom'), ('master', 'signs'), ('master', 'north'), ('age', 'position'), ('knee', 'stream'), ('bank', 'coat'), ('grand', 'horse'), ('dressed', 'trees'), ('coat', 'station'), ('john', 'l'), ('cloud', 'master'), ('beauty', 'distance'), ('building', 'flat'), ('grand', 'silent'), ('company', 'weight'), ('order', 'tone'), ('angry', 'listening'), ('c', 'food'), ('master', 'teeth'), ('nearly', 'raised'), ('bell', 'ears'), ('chin', 'grey'), ('bow', 'c'), ('knee', 'windows'), ('order', 'pink'), ('pair', 'weight'), ('f', 'tom'), ('dressed', 'showing'), ('growing', 'sick'), ('nose', 'system'), ('fifty', 'station'), ('afternoon', 'field'), ('fingers', 'window'), ('horse', 'raised'), ('clock', 'evening'), ('shadow', 'teeth'), ('completely', 'showing'), ('pictures', 'shadow'), ('grand', 'grey'), ('master', 'position'), ('signs', 'weight'), ('field', 'names'), ('coat', 'company'), ('pictures', 'table'), ('grass', 'station'), ('bank', 'pocket'), ('book', 'tone'), ('ears', 'shadow'), ('sees', 'thinks'), ('dinner', 'hat'), ('four', 'minutes'), ('fifty', 'john'), ('feet', 'window'), ('heads', 'neck'), ('field', 'john'), ('says', 'sees'), ('coat', 'dinner'), ('finger', 'window'), ('box', 'grey'), ('l', 'shock'), ('silence', 'view'), ('building', 'showing'), ('shaking', 'using'), ('coat', 'glass'), ('showing', 'silent'), ('f', 'fifty'), ('seven', 'station'), ('box', 'chin'), ('box', 'horse'), ('business', 'ears'), ('near', 'weak'), ('sharp', 'silent'), ('bow', 'john'), ('sharp', 'showing'), ('riding', 'showing'), ('eight', 'john'), ('chin', 'showing'), ('coat', 'north'), ('grey', 'master'), ('l', 'tom'), ('riding', 'written'), ('order', 'station'), ('coat', 'windows'), ('john', 'p'), ('l', 'master'), ('bell', 'nose'), ('bell', 'teeth'), ('building', 'horse'), ('master', 'minutes'), ('although', 'nearly'), ('bank', 'hat'), ('chair', 'tone'), ('north', 'page'), ('box', 'knee'), ('church', 'pair'), ('grey', 'l'), ('middle', 'point'), ('grand', 'showing'), ('master', 'ugly'), ('heavy', 'serious'), ('box', 'teeth'), ('grey', 'p'), ('chin', 'cup'), ('coat', 'l'), ('order', 'suit'), ('chin', 'wood'), ('bank', 'finger'), ('building', 'paper'), ('box', 'l'), ('heads', 'nose'), ('chair', 'stairs'), ('older', 'serious'), ('note', 'pair'), ('chair', 'stream'), ('cup', 'ears'), ('grand', 'sharp'), ('darkness', 'pictures'), ('chin', 'l'), ('l', 'minutes'), ('book', 'church'), ('eight', 'l'), ('distance', 'history'), ('chin', 'field'), ('chin', 'silver'), ('grey', 'north'), ('fifty', 'l'), ('b', 'john'), ('completely', 'using'), ('horse', 'showing'), ('field', 'master'), ('box', 'tone'), ('bank', 'neck'), ('edge', 'pictures'), ('chair', 'teeth'), ('grand', 'john'), ('double', 'e'), ('ears', 'grace'), ('date', 'path'), ('flat', 'kitchen'), ('box', 'field'), ('double', 'john'), ('horse', 'master'), ('box', 'company'), ('horse', 'l'), ('chin', 'grand'), ('grey', 'teeth'), ('grey', 'john'), ('horse', 'yellow'), ('box', 'fifty'), ('chin', 'tom'), ('john', 'ugly'), ('book', 'distance'), ('john', 'station'), ('church', 'table'), ('conversation', 'minutes'), ('tom', 'wood'), ('ears', 'glass'), ('afternoon', 'box'), ('business', 'hat'), ('box', 'position'), ('coat', 'field'), ('e', 'john'), ('completely', 'thin'), ('hearing', 'using'), ('horse', 'windows'), ('chair', 'nose'), ('bell', 'chin'), ('f', 'grand'), ('silent', 'thin'), ('de', 'double'), ('ears', 'grey'), ('table', 'trees'), ('glass', 'memory'), ('c', 'chin'), ('north', 'table'), ('master', 'path'), ('dinner', 'teeth'), ('cloud', 'coat'), ('chair', 'north'), ('grey', 'private'), ('book', 'teeth'), ('grey', 'shaking'), ('l', 'position'), ('dying', 'older'), ('calm', 'ugly'), ('pictures', 'teeth'), ('grand', 'master'), ('chair', 'system'), ('master', 'pair'), ('excited', 'paid'), ('chin', 'company'), ('doors', 'teeth'), ('position', 'wood'), ('c', 'grand'), ('bow', 'l'), ('box', 'north')]\n"
     ]
    }
   ],
   "source": [
    "movies_higher, lyrics_higher = find_interesting_pairs(movie_cos_sim, \n",
    "                                                    lyrics_cos_sim,\n",
    "                                                    min_difference=0.5,\n",
    "                                                    starting_threshold=0.7)\n",
    "\n",
    "print(len(movies_higher))\n",
    "print(movies_higher)\n",
    "print(len(lyrics_higher))\n",
    "print(lyrics_higher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the pairs for the lyrics dataset appear somewhat random. There is only one pair in the movie data that is significantly higher than in the lyrics data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary  \n",
    "  \n",
    "The analysis suggests a difference in topics between male and female authors in the dataset, and that female authors employ more descriptive languange, pairing a wider range of adjectives with nouns. Although a review of the embeddings for the lyrics data suggested that several relationships made sense, there were some unusual pairings compared to the other data which seem to be driven by a sparsity of words at the lower frequency range.\n",
    "\n",
    "Overall, further work will be required in order to uncover hidden bias. The next section will focus on implicit associations revealed by the authors use of emotive language."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
